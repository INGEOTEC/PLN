# Mezcla de Modelos

El **objetivo** de la unidad es 

## Paquetes usados {.unnumbered}

```{python}
#| echo: true
from EvoMSA import BoW, DenseBoW, StackGeneralization
from microtc.utils import tweet_iterator
from IngeoML import CI, SelectFromModelCV
from sklearn.metrics import f1_score,\
                            recall_score,\
                            precision_score
from wordcloud import WordCloud                            
import numpy as np
import pandas as pd
from matplotlib import pylab as plt
import seaborn as sns
```

```{python}
#| echo: false
from IPython.display import Markdown
```

```{python}
#| echo: false
#| output: false
from os.path import isfile, isdir
from EvoMSA.utils import Download
from EvoMSA import utils
utils.USE_TQDM = False
if not isfile('delitos.zip'):
    Download('https://github.com/INGEOTEC/Delitos/releases/download/Datos/delitos.zip',
             'delitos.zip')
if not isdir('delitos'):
    !unzip -Pingeotec delitos.zip
```

::: {.content-visible when-format="html"}
---

**Video explicando la unidad**

---
:::

## Conjunto de Datos 

El conjunto de datos se puede conseguir en la página de [Delitos](https://ingeotec.github.io/Delitos) aunque en esta dirección es necesario poblar los textos dado que solamente se encuentra el identificador del Tweet.

Para leer los datos del conjunto de entrenamiento y prueba se utilizan las siguientes instrucciones. En la variable `D` se tiene los datos que se utilizarán para entrenar el clasificador basado en la bolsa de palabras y en `Dtest` los datos del conjunto de prueba, que son usados para medir el rendimiento del clasificador.

```{python}
#| echo: true
fname = 'delitos/delitos_ingeotec_Es_train.json'
fname_test = 'delitos/delitos_ingeotec_Es_test.json'
D = list(tweet_iterator(fname))
Dtest = list(tweet_iterator(fname_test))
```

En la siguiente instrucción se observa el primer elemento del conjunto de entrenamiento. Se puede observar que en el campo `text` se encuentra el texto, el campo `klass` representa la etiqueta o clase, donde $0$ representa la clase negativa y $1$ la clase positiva, es decir, la presencia de un delito. El campo `id` es el identificador del Tweet y `annotations` son las clases dadas por los etiquetadores a ese ejemplo.

```{python}
#| echo: true
D[81]
```

## Bolsa de Palabras Dispersa 

Se inicia con la creación de un clasificador basado en una bolsa de palabras dispersa, el clasificador es una máquina de soporte vectorial lineal (`LinearSVC`). La siguiente instrucción usa la clase `BoW` para crear este clasificador de texto. El primer paso es seleccionar el lenguaje, en este caso español (es) y después se entrena usando el método `fit`.

```{python}
#| echo: true
bow = BoW(lang='es').fit(D)
```

```{python}
#| echo: true
txt = 'me golpearon y robaron la bicicleta en la noche'
bow.predict([txt])
```

```{python}
#| echo: true
hy_bow = bow.predict(Dtest)
```

```{python}
#| echo: true
y = np.r_[[x['klass'] for x in Dtest]]
f1_score(y, hy_bow, average=None)
```

```{python}
#| echo: true
ci = CI(statistic=lambda y, hy: f1_score(y, hy, 
                                         average=None))
ci_izq, ci_der = ci(y, hy_bow)
```

```{python}
#| echo: false
ci_izq_f = ', '.join([f'{v:0.4f}' for v in ci_izq])
ci_izq_f = Markdown(f'$[{ci_izq_f}]$')
ci_der_f = ', '.join([f'{v:0.4f}' for v in ci_der])
ci_der_f = Markdown(f'$[{ci_der_f}]$')
```

El intervalo izquierdo es `{python} ci_izq_f` y el derecho tiene los valores `{python} ci_der_f`.

```{python}
#| code-fold: true
#| fig-cap: Histograma de f1 por clase
#| label: hist-f1-bow
df_bow = pd.DataFrame(ci.statistic_samples, columns=['f1-neg', 'f1-pos'])
df_bow['Tipo'] = 'BoW'
sns.set_style('whitegrid')
sns.displot(df_bow, kde=True)
```

```{python}
#| echo: true
ws = bow.estimator_instance.coef_[0]
idfs = bow.weights
```

```{python}
#| echo: true
tokens_pos = {name: w * idf
              for name, idf, w in zip(bow.names,
                                      idfs, ws)
              if w > 0}
tokens_neg = {name: w * idf * -1
              for name, idf, w in zip(bow.names,
                                      idfs, ws)
              if w < 0}
```


```{python}
#| code-fold: true
#| fig-cap: Nubes de tokens positivos y negativos
#| label: fig-nube-tokens
word_pos = WordCloud().generate_from_frequencies(tokens_pos)
word_neg = WordCloud().generate_from_frequencies(tokens_neg)

fig, (ax1, ax2) = plt.subplots(1, 2)

for cloud, ax, title in zip([word_pos, word_neg],
                     [ax1, ax2],
                     ['Positivas', 'Negativas']):
    ax.imshow(cloud, interpolation='bilinear')
    ax.grid(False)
    ax.tick_params(left=False, right=False, labelleft=False,
                   labelbottom=False, bottom=False)
    ax.set_title(title)
```


## Bolsa de Palabras Densas 

```{python}
#| echo: true
dense = DenseBoW(lang='es',
                 voc_size_exponent=15,
                 dataset=False)
```

```{python}
#| echo: true
#| output: false
macro_f1 = lambda y, hy: f1_score(y, hy, average='macro')
kwargs = dense.estimator_kwargs
estimator = dense.estimator_class(**kwargs)
kwargs = dict(estimator=estimator,
              scoring=macro_f1)
dense.select(D=D,
             feature_selection=SelectFromModelCV,
             feature_selection_kwargs=kwargs)
dense.fit(D)
```

```{python}
#| echo: true
select = dense.feature_selection
perf = select.cv_results_
```

```{python}
#| code-fold: true
#| fig-cap: Rendimiento Variando el Número de Características
#| label: fig-dense-k
_ = [{'d': k, 'macro-f1': v} for k, v in perf.items()]
df = pd.DataFrame(_)
ax = sns.lineplot(df, x='d', y='macro-f1')
sns.set_style('whitegrid')
```

```{python}
#| echo: true
hy_dense = dense.predict(Dtest)
```

```{python}
#| echo: true
f1_score(y, hy_dense, average=None)
```

```{python}
#| code-fold: true
#| fig-cap: Histogramas de f1 por clase
#| label: hist-f1-bow-dense
ci(y, hy_dense)
df_dense = pd.DataFrame(ci.statistic_samples, columns=['f1-neg', 'f1-pos'])
df_dense['Tipo'] = 'Dense'

_ = df_bow.melt(id_vars=['Tipo'], value_name='value', var_name='f1')
_2 = df_dense.melt(id_vars=['Tipo'], value_name='value', var_name='f1')
_ = pd.concat((_, _2))
sns.set_style("whitegrid")
fig = sns.displot(_, x='value', hue='f1', kde=True, col='Tipo')
# plt.grid()
```

```{python}
#| echo: true
w = dense.estimator_instance.coef_[0]
names = np.array(dense.names)
carac_pos = {k: v for k, v in zip(names, w) if v > 0}
carac_neg = {k: v * -1 for k, v in zip(names, w) if v < 0}
```


```{python}
#| code-fold: true
#| fig-cap: Nube de características positivas y negativas
#| label: fig-nube-densa
word_pos = WordCloud().generate_from_frequencies(carac_pos)
word_neg = WordCloud().generate_from_frequencies(carac_neg)

fig, (ax1, ax2) = plt.subplots(1, 2)

for cloud, ax, title in zip([word_pos, word_neg],
                     [ax1, ax2],
                     ['Positivas', 'Negativas']):
    ax.imshow(cloud, interpolation='bilinear')
    ax.grid(False)
    ax.tick_params(left=False, right=False, labelleft=False,
                   labelbottom=False, bottom=False)
    ax.set_title(title)
```

## Análisis Mediante Ejemplos 

```{python}
bow_norm = np.linalg.norm(bow.estimator_instance.coef_[0])
txt = 'Asesinan a persona en Jalisco.'
bow.decision_function([txt]) / bow_norm
```

```{python}
dense_norm = np.linalg.norm(dense.estimator_instance.coef_[0])
dense.decision_function([txt]) / dense_norm
```

```{python}
txt = 'La asesina vivía en Jalisco.'
bow.decision_function([txt]) / bow_norm
```

```{python}
dense.decision_function([txt]) / dense_norm
```

```{python}
txt = 'Asesinan a persona en Jalisco.'
bow.decision_function([txt]) / bow_norm
```

```{python}
w = bow.estimator_instance.coef_[0]
vec = bow.bow[txt]
sorted([(bow.names[k], w[k] * v) for k, v in vec],
       key=lambda x: np.fabs(x[1]), reverse=True)[:5]
```

```{python}
dense.decision_function([txt]) / dense_norm
```

```{python}
w = dense.estimator_instance.coef_[0]
vec = dense.transform([txt])[0] * w
sorted([(dense.names[k], v) for k, v in enumerate(vec)],
       key=lambda x: np.fabs(x[1]), reverse=True)[:5]
```


```{python}
#| code-fold: true
#| fig-cap: Nube de características ejemplo positivo
#| label: fig-nube-ej-pos
def codifica(names, vec):
    carac_pos = dict()
    for k, v in zip(names, vec):
        if v > 0:
            key = f'{k.upper()}'
        else:
            key = k
        carac_pos[key] = np.fabs(v)
    return carac_pos
txt = 'Asesinan a persona en Jalisco.'
_ = dense.transform([txt])[0] * dense.estimator_instance.coef_[0]
word_cloud_dense = WordCloud().generate_from_frequencies(codifica(dense.names, _))
 
w = bow.estimator_instance.coef_[0]
vec = bow.bow[txt]
carac_pos = dict()
for k, v in vec:
    if w[k] > 0:
        key = f'{bow.names[k].upper()}'
    else:
        key = bow.names[k]
    carac_pos[key] = np.fabs(v * w[k])

word_cloud = WordCloud().generate_from_frequencies(carac_pos)

fig, (ax1, ax2) = plt.subplots(1, 2)
ax1.imshow(word_cloud, interpolation='bilinear')
ax2.imshow(word_cloud_dense, interpolation='bilinear')
for ax, title in zip([ax1, ax2], ['BoW', 'DenseBoW']):
    ax.grid(False)
    ax.tick_params(left=False, right=False, labelleft=False,
                   labelbottom=False, bottom=False)
    ax.set_title(title)
```


```{python}
#| code-fold: true
#| fig-cap: Nube de características ejemplo negativo
#| label: fig-nube-ej
txt = 'La asesina vivía en Jalisco.'
_ = dense.transform([txt])[0] * dense.estimator_instance.coef_[0]
word_cloud_dense = WordCloud().generate_from_frequencies(codifica(dense.names, _))
 
w = bow.estimator_instance.coef_[0]
vec = bow.bow[txt]
carac_pos = dict()
for k, v in vec:
    if w[k] > 0:
        key = f'{bow.names[k].upper()}'
    else:
        key = bow.names[k]
    carac_pos[key] = np.fabs(v * w[k])

word_cloud = WordCloud().generate_from_frequencies(carac_pos)

fig, (ax1, ax2) = plt.subplots(1, 2)
ax1.imshow(word_cloud, interpolation='bilinear')
ax2.imshow(word_cloud_dense, interpolation='bilinear')
for ax, title in zip([ax1, ax2], ['BoW', 'DenseBoW']):
    ax.grid(False)
    ax.tick_params(left=False, right=False, labelleft=False,
                   labelbottom=False, bottom=False)
    ax.set_title(title)
```


```{python}
#| code-fold: true
#| fig-cap: Nube de características en un ejemplo positivo con predicción negativa
#| label: fig-nube-ej-error
txt = 'Le acaban de robar la bicicleta a mi hijo.'
_ = dense.transform([txt])[0] * dense.estimator_instance.coef_[0]
word_cloud_dense = WordCloud().generate_from_frequencies(codifica(dense.names, _))
 
w = bow.estimator_instance.coef_[0]
vec = bow.bow[txt]
carac_pos = dict()
for k, v in vec:
    if w[k] > 0:
        key = f'{bow.names[k].upper()}'
    else:
        key = bow.names[k]
    carac_pos[key] = np.fabs(v * w[k])

word_cloud = WordCloud().generate_from_frequencies(carac_pos)

fig, (ax1, ax2) = plt.subplots(1, 2)
ax1.imshow(word_cloud, interpolation='bilinear')
ax2.imshow(word_cloud_dense, interpolation='bilinear')
for ax, title in zip([ax1, ax2], ['BoW', 'DenseBoW']):
    ax.grid(False)
    ax.tick_params(left=False, right=False, labelleft=False,
                   labelbottom=False, bottom=False)
    ax.set_title(title)
```

## Combinando Modelos

```{python}
#| echo: true
stack = StackGeneralization([bow, dense]).fit(D)
```

```{python}
#| echo: true
hy_stack = stack.predict(Dtest)
```

```{python}
#| echo: true
f1_score(y, hy_stack, average=None)
```


```{python}
#| label: tbl-performance-recall-precision-delitos
#| tbl-cap: Rendimiento
#| echo: false
headers = '|              |   Recall neg | Recall pos | Precision neg | Precision pos |'
linea =   '|--------------|--------------|------------|---------------|---------------|'

recall_bow = recall_score(y, hy_bow, average=None)
recall_dense = recall_score(y, hy_dense, average=None)
recall_stack = recall_score(y, hy_stack, average=None)
pr_bow = precision_score(y, hy_bow, average=None)
pr_dense = precision_score(y, hy_dense, average=None)
pr_stack = precision_score(y, hy_stack, average=None)

recall_bow_f = ' | '.join([f'${x:0.4f}$' for x in np.r_[recall_bow, pr_bow]])
recall_dense_f = ' | '.join([f'${x:0.4f}$' for x in np.r_[recall_dense, pr_dense]])
recall_stack_f = ' | '.join([f'${x:0.4f}$' for x in np.r_[recall_stack, pr_stack]])

tab = '\n'.join(([headers, linea,
                  f'|`bow`|{recall_bow_f}|',
                  f'|`dense`|{recall_dense_f}|',
                  f'|`stack`|{recall_stack_f}|']))
Markdown(tab)
```

```{python}
#| label: tbl-performance-f1-delitos
#| tbl-cap: Rendimiento
#| echo: false
headers = '|              | f1 neg | f1 pos | macro-f1 |'
linea =   '|--------------|--------|--------|----------|'

f1_bow =   f1_score(y, hy_bow, average=None)
f1_dense = f1_score(y, hy_dense, average=None)
f1_stack = f1_score(y, hy_stack, average=None)

f1_macro_bow =   f1_score(y, hy_bow,   average="macro")
f1_macro_dense = f1_score(y, hy_dense, average="macro")
f1_macro_stack = f1_score(y, hy_stack, average="macro")


recall_bow_f = ' | '.join([f'${x:0.4f}$' for x in   np.r_[f1_bow, f1_macro_bow]])
recall_dense_f = ' | '.join([f'${x:0.4f}$' for x in np.r_[f1_dense, f1_macro_dense]])
recall_stack_f = ' | '.join([f'${x:0.4f}$' for x in np.r_[f1_stack, f1_macro_stack]])

tab = '\n'.join(([headers, linea,
                  f'|`bow`|{recall_bow_f}|',
                  f'|`dense`|{recall_dense_f}|',
                  f'|`stack`|{recall_stack_f}|']))
Markdown(tab)
```