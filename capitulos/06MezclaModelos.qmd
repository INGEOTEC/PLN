# Mezcla de Modelos

El **objetivo** de la unidad es 

## Paquetes usados {.unnumbered}

```{python}
#| echo: true
from EvoMSA import BoW, DenseBoW
from microtc.utils import tweet_iterator
from IngeoML import CI, SelectFromModelCV
from sklearn.metrics import f1_score
import numpy as np
```

```{python}
#| echo: false
from IPython.display import Markdown
```

```{python}
#| echo: false
#| output: false
from os.path import isfile, isdir
from EvoMSA.utils import Download
from EvoMSA import utils
utils.USE_TQDM = False
if not isfile('delitos.zip'):
    Download('https://github.com/INGEOTEC/Delitos/releases/download/Datos/delitos.zip',
             'delitos.zip')
if not isdir('delitos'):
    !unzip -Pingeotec delitos.zip
```

::: {.content-visible when-format="html"}
---

**Video explicando la unidad**

---
:::

## Conjunto de Datos 

El conjunto de datos se puede conseguir en la p치gina de [Delitos](https://ingeotec.github.io/Delitos) aunque en esta direcci칩n es necesario poblar los textos dado que solamente se encuentra el identificador del Tweet.

Para leer los datos del conjunto de entrenamiento y prueba se utilizan las siguientes instrucciones. En la variable `D` se tiene los datos que se utilizar치n para entrenar el clasificador basado en la bolsa de palabras y en `Dtest` los datos del conjunto de prueba, que son usados para medir el rendimiento del clasificador.

```{python}
#| echo: true
fname = 'delitos/delitos_ingeotec_Es_train.json'
fname_test = 'delitos/delitos_ingeotec_Es_test.json'
D = list(tweet_iterator(fname))
Dtest = list(tweet_iterator(fname_test))
```

En la siguiente instrucci칩n se observa el primer elemento del conjunto de entrenamiento. Se puede observar que en el campo `text` se encuentra el texto, el campo `klass` representa la etiqueta o clase, donde $0$ representa la clase negativa y $1$ la clase positiva, es decir, la presencia de un delito. El campo `id` es el identificador del Tweet y `annotations` son las clases dadas por los etiquetadores a ese ejemplo.

```{python}
#| echo: true
D[81]
```

## Bolsa de Palabras Dispersa 

```{python}
#| echo: true
bow = BoW(lang='es').fit(D)
```

```{python}
#| echo: true
txt = 'me golpearon y robaron la bicicleta en la noche'
bow.predict([txt])
```

```{python}
#| echo: true
hy = bow.predict(Dtest)
```

```{python}
#| echo: true
y = np.r_[[x['klass'] for x in Dtest]]
f1_score(y, hy, average=None)
```

```{python}
#| echo: true
ci = CI(statistic=lambda y, hy: f1_score(y, hy, 
                                         average=None))
ci_izq, ci_der = ci(y, hy)
```

```{python}
#| echo: false
ci_izq_f = ', '.join([f'{v:0.4f}' for v in ci_izq])
ci_izq_f = Markdown(f'$[{ci_izq_f}]$')
ci_der_f = ', '.join([f'{v:0.4f}' for v in ci_der])
ci_der_f = Markdown(f'$[{ci_der_f}]$')
```

El intervalo izquierdo es `{python} ci_izq_f` y el derecho tiene los valores `{python} ci_der_f`.

## Bolsa de Palabras Densas 

```{python}
#| echo: true
dense = DenseBoW(lang='es', 
                 voc_size_exponent=15,
                 dataset=False)
```

```{python}
#| echo: true
#| output: false
macro_f1 = lambda y, hy: f1_score(y, hy, average='macro')
kwargs = dense.estimator_kwargs
estimator = dense.estimator_class(**kwargs)
kwargs = dict(estimator=estimator,
              scoring=macro_f1)
dense.select(D=D,
             feature_selection=SelectFromModelCV,
             feature_selection_kwargs=kwargs)
dense.fit(D)
```


