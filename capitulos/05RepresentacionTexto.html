<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.550">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Procesamiento de Lenguaje Natural - 5&nbsp; Representación de Texto</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../capitulos/06ClasificacionTexto.html" rel="next">
<link href="../capitulos/04FundamentosCT.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>
<script src="../site_libs/quarto-diagram/mermaid.min.js"></script>
<script src="../site_libs/quarto-diagram/mermaid-init.js"></script>
<link href="../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../capitulos/05RepresentacionTexto.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Representación de Texto</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Procesamiento de Lenguaje Natural</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/INGEOTEC/PLN" title="Ejecutar el código" class="quarto-navigation-tool px-1" aria-label="Ejecutar el código"><i class="bi bi-github"></i></a>
    <a href="../Procesamiento-de-Lenguaje-Natural.pdf" title="Descargar PDF" class="quarto-navigation-tool px-1" aria-label="Descargar PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefacio</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/01Introduccion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introducción</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/02ManejandoTexto.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Manejando Texto</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/03ModeladoLenguaje.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Modelado de Lenguaje</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/04FundamentosCT.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Fundamentos de Clasificación de Texto</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/05RepresentacionTexto.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Representación de Texto</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/06ClasificacionTexto.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Clasificación de Texto</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/07TareasClasificacion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Tareas de Clasificación de Texto</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/08BasesConocimiento.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Bases de Conocimiento</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/09Visualizacion.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Visualización</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/10Conclusiones.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Conclusiones</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../capitulos/11Referencias.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Referencias</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#paquetes-usados" id="toc-paquetes-usados" class="nav-link active" data-scroll-target="#paquetes-usados">Paquetes usados</a></li>
  <li><a href="#bolsa-de-palabras-dispersa" id="toc-bolsa-de-palabras-dispersa" class="nav-link" data-scroll-target="#bolsa-de-palabras-dispersa"><span class="header-section-number">5.1</span> Bolsa de Palabras Dispersa</a>
  <ul class="collapse">
  <li><a href="#pesado-de-términos" id="toc-pesado-de-términos" class="nav-link" data-scroll-target="#pesado-de-términos"><span class="header-section-number">5.1.1</span> Pesado de Términos</a></li>
  <li><a href="#sec-bolsa-dispersa-ejemplos" id="toc-sec-bolsa-dispersa-ejemplos" class="nav-link" data-scroll-target="#sec-bolsa-dispersa-ejemplos"><span class="header-section-number">5.1.2</span> Ejemplos</a></li>
  </ul></li>
  <li><a href="#bolsa-de-palabras-densa" id="toc-bolsa-de-palabras-densa" class="nav-link" data-scroll-target="#bolsa-de-palabras-densa"><span class="header-section-number">5.2</span> Bolsa de Palabras Densa</a>
  <ul class="collapse">
  <li><a href="#ejemplos" id="toc-ejemplos" class="nav-link" data-scroll-target="#ejemplos"><span class="header-section-number">5.2.1</span> Ejemplos</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Representación de Texto</span></h1><button type="button" class="btn code-tools-button dropdown-toggle" id="quarto-code-tools-menu" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi"></i> Código</button><ul class="dropdown-menu dropdown-menu-end" aria-labelelledby="quarto-code-tools-menu"><li><a id="quarto-show-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Mostrar todo el código</a></li><li><a id="quarto-hide-all-code" class="dropdown-item" href="javascript:void(0)" role="button">Ocultar todo el código</a></li><li><hr class="dropdown-divider"></li><li><a id="quarto-view-source" class="dropdown-item" href="javascript:void(0)" role="button">Ver el código fuente</a></li></ul></div></div>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>El <strong>objetivo</strong> de la unidad es</p>
<section id="paquetes-usados" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="paquetes-usados">Paquetes usados</h2>
<div id="171b6641" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> EvoMSA <span class="im">import</span> BoW,<span class="op">\</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>                   DenseBoW</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> microtc.utils <span class="im">import</span> tweet_iterator</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> wordcloud <span class="im">import</span> WordCloud                            </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pylab <span class="im">as</span> plt</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
<p><strong>Video explicando la unidad</strong></p>
<hr>
</section>
<section id="bolsa-de-palabras-dispersa" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="bolsa-de-palabras-dispersa"><span class="header-section-number">5.1</span> Bolsa de Palabras Dispersa</h2>
<p>La idea de una bolsa de palabras discretas es que después de haber normalizado y segmentado el texto (<a href="02ManejandoTexto.html" class="quarto-xref"><span>Capítulo 2</span></a>), cada token <span class="math inline">\(t\)</span> sea asociado a un vector único <span class="math inline">\(\mathbf{v_t} \in \mathbb R^d\)</span> donde la <span class="math inline">\(i\)</span>-ésima componente, i.e., <span class="math inline">\(\mathbf{v_t}_i\)</span>, es diferente de cero y <span class="math inline">\(\forall_{j \neq i} \mathbf{v_t}_j=0\)</span>. Es decir la <span class="math inline">\(i\)</span>-ésima componente está asociada al token <span class="math inline">\(t\)</span>, se podría pensar que si el vocabulario está ordenado de alguna manera, entonces el token <span class="math inline">\(t\)</span> está en la posición <span class="math inline">\(i\)</span>. Por otro lado el valor que contiene la componente se usa para representar alguna característica del token.</p>
<p>El conjunto de vectores <span class="math inline">\(\mathbf v\)</span> corresponde al vocabulario, teniendo <span class="math inline">\(d\)</span> diferentes token en el mismo y por definición <span class="math inline">\(\forall_{i \neq j} \mathbf{v_i} \cdot \mathbf{v_j} = 0\)</span>, donde <span class="math inline">\(\mathbf{v_i} \in \mathbb R^d\)</span>, <span class="math inline">\(\mathbf{v_j} \in \mathbb R^d\)</span>, y <span class="math inline">\((\cdot)\)</span> es el producto punto. Cabe mencionar que cualquier token fuera del vocabulario es descartado.</p>
<p>Usando esta notación, un texto <span class="math inline">\(x\)</span> está representado por una secuencia de términos, i.e., <span class="math inline">\((t_1, t_2, \ldots)\)</span>; la secuencia puede tener repeticiones es decir, <span class="math inline">\(t_j = t_k\)</span>. Utilizando la característica de que cada token está asociado a un vector <span class="math inline">\(\mathbf v\)</span>, se transforma la secuencia de términos a una secuencia de vectores (manteniendo las repeticiones), i.e., <span class="math inline">\((\mathbf{v_{t_1}}, \mathbf{v_{t_2}}, \ldots)\)</span>. Finalmente, el texto <span class="math inline">\(x\)</span> se representa como:</p>
<p><span id="eq-bolsa-palabras"><span class="math display">\[
\mathbf x = \frac{\sum_t \mathbf{v_t}}{\lVert \sum_t \mathbf{v_t} \rVert},
\tag{5.1}\]</span></span></p>
<p>donde la suma se hace para todos los elementos de la secuencia, <span class="math inline">\(\mathbf x \in \mathbb R^d\)</span>, y <span class="math inline">\(\lVert \mathbf w \rVert\)</span> es la norma Euclideana del vector <span class="math inline">\(\mathbf w.\)</span></p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div id="fig-repr-texto-bolsa-dispersa" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-repr-texto-bolsa-dispersa-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<pre class="mermaid mermaid-js" data-label="fig-repr-texto-bolsa-dispersa">flowchart LR
    Terminos([Texto\n Segmentado]) -- Pre-entrenados --&gt;  A[Asociación]
    Terminos --&gt; Entrenamiento[Estimación\n de Pesos]
    Corpus([Corpus]) -.-&gt; Entrenamiento
    Entrenamiento --&gt; A
    A --&gt; Repr([Representación])
</pre>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-repr-texto-bolsa-dispersa-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;5.1: Diagrama Bolsa de Palabras Dispersa
</figcaption>
</figure>
</div>
</div>
</div>
<p>Antes de iniciar la descripción detallada del proceso de representación utilizando una bolsa de palabras dispersas, es conveniente ilustrar este proceso mediante la <a href="#fig-repr-texto-bolsa-dispersa" class="quarto-xref">Figura&nbsp;<span>5.1</span></a>. El <strong>texto segmentado</strong> es el resultado del proceso ilustrado en <a href="02ManejandoTexto.html#fig-pre-procesamiento" class="quarto-xref">Figura&nbsp;<span>2.1</span></a>. El texto segmentado puede seguir dos caminos, en la parte superior se encuentra el caso cuando los pesos han sido identificados previamente y en la parte inferior es el procedimiento cuando los pesos se estiman mediante un corpus específico que normalmente es un conjunto de entrenamiento.</p>
<section id="pesado-de-términos" class="level3" data-number="5.1.1">
<h3 data-number="5.1.1" class="anchored" data-anchor-id="pesado-de-términos"><span class="header-section-number">5.1.1</span> Pesado de Términos</h3>
<p>Como se había mencionado el valor que tiene la componente <span class="math inline">\(i\)</span>-ésima del vector <span class="math inline">\(\mathbf{v_t}_i\)</span> corresponde a una característica del término asociado, este procedimiento se le conoce como el <strong>esquema de pesado</strong>. Por ejemplo, si el valor es <span class="math inline">\(1\)</span> (i.e., <span class="math inline">\(\mathbf{v_{t_i}} = 1\)</span>) entonces el valor está indicando solo la presencia del término, este es el caso más simple. Considerando la <a href="#eq-bolsa-palabras" class="quarto-xref">Ecuación&nbsp;<span>5.1</span></a> se observa que el resultado, <span class="math inline">\(\mathbf x\)</span>, cuenta las repeticiones de cada término, por esta característica a este esquema se le conoce como <strong>frecuencia de términos</strong> (<em>term frequency (TF)</em>).</p>
<p>Una medida que complementa la información que tiene la frecuencia de términos es el inverso de la frecuencia del término (<em>Inverse Document Frequency (IDF)</em>) en la colección, esta medida propuesta por <span class="citation" data-cites="Jones1972">Sparck Jones (<a href="11Referencias.html#ref-Jones1972" role="doc-biblioref">1972</a>)</span> se usa en un método de pesado descrito por <span class="citation" data-cites="Salton1973">Salton y Yang (<a href="11Referencias.html#ref-Salton1973" role="doc-biblioref">1973</a>)</span> el cual es conocido como <strong>TFIDF</strong>. Este método de pesado propone el considerar el producto de la frecuencia del término y el inverso de la frecuencia del término (<em>Inverse Document Frequency (IDF)</em> ) en la colección como el peso del término.</p>
</section>
<section id="sec-bolsa-dispersa-ejemplos" class="level3" data-number="5.1.2">
<h3 data-number="5.1.2" class="anchored" data-anchor-id="sec-bolsa-dispersa-ejemplos"><span class="header-section-number">5.1.2</span> Ejemplos</h3>
<p>En los siguientes ejemplos se usa una bolsa de palabras con un pesado TFIDF pre-entrenada, los datos de esta bolsa de palabras se encuentra en el atributo <code>BoW.bow</code>. El tamaño del vocabulario es <span class="math inline">\(131072\)</span>, que está compuesto por palabras, gramas de palabras y caracteres. En el siguiente ejemplo se muestran los primeros tres gramas con sus respectivos valores TFIDF de la frase <em>Buen día</em>. Se puede observar que el <code>tm</code> regresa una lista de pares, donde la primera parte es el identificador del término, e.g., <span class="math inline">\(11219\)</span> y el segundo es el valor TFIDF, e.g., <span class="math inline">\(0.3984\)</span>. La lista tiene un tamaño de <span class="math inline">\(27\)</span> elementos, el resto de los <span class="math inline">\(131072\)</span> componentes son cero dado que no se encuentran en el texto representado.</p>
<div id="a9fdc099" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>bow <span class="op">=</span> BoW(lang<span class="op">=</span><span class="st">'es'</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>tm <span class="op">=</span> bow.bow</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>vec <span class="op">=</span> tm[<span class="st">'Buen día'</span>]</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>vec[:<span class="dv">3</span>]</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="5">
<pre><code>[(11219, 0.3984336285263178),
 (11018, 0.3245843730253675),
 (24409, 0.2377856890280623)]</code></pre>
</div>
</div>
<p>El uso del identificador del término se puede reemplazar por el término para poder visualizar mejor la representación del texto en el espacio vectorial. El diccionario que se encuentra en <code>BoW.names</code> hace la relación identificador a término. Se puede ver que el primer elemento del vector es el bigrama <em>buen~dia</em>, seguido por <em>buen</em> y el tercer término es <em>dia</em>. Los siguientes términos que no se muestran corresponden a gramas de caracteres. El valor TFIDF no indica la importancia del término, mientras mayor sea el valor, se considera más importante de acuerdo al TFIDF. En este ejemplo el bigrama tiene más importancia que las palabras y la palabra <em>buen</em> es más significativa que <em>dia</em>.</p>
<div id="7e2cd66d" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>[(bow.names[k], v)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a> <span class="cf">for</span> k, v <span class="kw">in</span> vec[:<span class="dv">3</span>]]</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>[('buen~dia', 0.3984336285263178),
 ('buen', 0.3245843730253675),
 ('dia', 0.2377856890280623)]</code></pre>
</div>
</div>
<p>Con el objetivo de ilustrar una heurística que ha dado buenos resultados en el siguiente ejemplo se presentan las primeras cuatro componentes del texto <em>Buen día colegas</em>. Se puede observar como los valores de IDF de los términos comunes cambiaron, por ejemplo para el caso de <em>buen~dia</em> cambio de <span class="math inline">\(0.3984\)</span> a <span class="math inline">\(0.2486\)</span>. Este es el resultado de que los valores están normalizados tal como se muestra en la <a href="#eq-bolsa-palabras" class="quarto-xref">Ecuación&nbsp;<span>5.1</span></a>. Por otro lado, se observa que ahora el término más significativo es la palabra <em>colegas</em>.</p>
<div id="9e3a1268" class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="st">'Buen día colegas'</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>[(tm.id2token[k], v)</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a> <span class="cf">for</span> k, v <span class="kw">in</span> tm[txt][:<span class="dv">4</span>]]</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>[('buen~dia', 0.24862785236357487),
 ('buen', 0.20254494048246244),
 ('dia', 0.1483814139998851),
 ('colegas', 0.3538047214393573)]</code></pre>
</div>
</div>
<p>Una manera de visualizar la representación es creando una nube de palabras de los términos, donde el tamaño del termino corresponde al valor TFIDF. En la <a href="#fig-repr-texto-nube" class="quarto-xref">Figura&nbsp;<span>5.2</span></a> muestra la nube de palabras generada con los términos y sus respectivos valores IDF del texto <em>Es un placer estar platicando con ustedes.</em></p>
<div id="cell-fig-repr-texto-nube" class="cell" data-execution_count="9">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="st">'Es un placer estar platicando con ustedes.'</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> {tm.id2token[<span class="bu">id</span>]: v <span class="cf">for</span> <span class="bu">id</span>, v <span class="kw">in</span> tm[txt]}</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>word_cloud <span class="op">=</span> WordCloud().generate_from_frequencies(tokens)</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>plt.imshow(word_cloud, interpolation<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">False</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>plt.tick_params(left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>                labelbottom<span class="op">=</span><span class="va">False</span>, bottom<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-repr-texto-nube" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-repr-texto-nube-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="05RepresentacionTexto_files/figure-html/fig-repr-texto-nube-output-1.png" width="540" height="280" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-repr-texto-nube-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;5.2: Nube de términos
</figcaption>
</figure>
</div>
</div>
</div>
<p>El texto se representa en un espacio vectorial, entonces es posible comparar la similitud entre dos textos en esta representación, por ejemplo, en el siguiente ejemplo se compara la similitud coseno entre los textos <em>Es un placer estar platicando con ustedes.</em> y <em>La lluvia genera un caos en la ciudad.</em> El valor obtenido es cercano a cero indicando que estos textos no son similares.</p>
<div id="08ac3949" class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>txt1 <span class="op">=</span> <span class="st">'Es un placer estar platicando con ustedes.'</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>txt2 <span class="op">=</span> <span class="st">'La lluvia genera un caos en la ciudad.'</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>vec1 <span class="op">=</span> tm[txt1]</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>vec2 <span class="op">=</span> tm[txt2]</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> {k: v <span class="cf">for</span> k, v <span class="kw">in</span> vec1}</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>np.<span class="bu">sum</span>([f[k] <span class="op">*</span> v <span class="cf">for</span> k, v <span class="kw">in</span> vec2 <span class="cf">if</span> k <span class="kw">in</span> f])</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="10">
<pre><code>0.01645519294478695</code></pre>
</div>
</div>
<p>Complementando el ejemplo anterior, en esta ocasión se comparan dos textos que comparten el concepto <em>plática</em>, estos son <em>Es un placer estar platicando con ustedes.</em> y <em>Estoy dando una platica en Morelia.</em> se puede observar que estos textos son más similares que los ejemplos anteriores.</p>
<div id="d68600e0" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a>txt1 <span class="op">=</span> <span class="st">'Es un placer estar platicando con ustedes.'</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>txt2 <span class="op">=</span> <span class="st">'Estoy dando una platica en Morelia.'</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>vec1 <span class="op">=</span> tm[txt1]</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>vec2 <span class="op">=</span> tm[txt2]</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> {k: v <span class="cf">for</span> k, v <span class="kw">in</span> vec1}</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>np.<span class="bu">sum</span>([f[k] <span class="op">*</span> v <span class="cf">for</span> k, v <span class="kw">in</span> vec2 <span class="cf">if</span> k <span class="kw">in</span> f])</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>0.2035427118119315</code></pre>
</div>
</div>
<p>Habiendo realizado la similitud entre algunos textos lleva a preguntarse cómo será la distribución de similitud entre varios textos, para poder contestar esta pregunta, se utilizarán los datos de <a href="https://ingeotec.github.io/Delitos">Delitos</a>, los cuales se guardan en la variable <code>D</code> tal y como se en las siguientes instrucciones.</p>
<div id="6c0fed00" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>fname <span class="op">=</span> <span class="st">'delitos/delitos_ingeotec_Es_train.json'</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>D <span class="op">=</span> <span class="bu">list</span>(tweet_iterator(fname))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>El primer paso es representar todos los textos en el espacio vectorial de la bolsa de palabras, lo cual se logra con el método <code>BoW.transform</code> (primera linea), el segundo paso es calcular la similitud entre todos los textos, como se muestra en la segunda linea.</p>
<div id="18cecca8" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> tm.transform(D)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>sim <span class="op">=</span> np.dot(X, X.T)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>La distribución de similitud se muestra en la <a href="#fig-text-repr-similitud-bow" class="quarto-xref">Figura&nbsp;<span>5.3</span></a> se puede observar que las similitudes se encuentran concentradas cerca del cero, esto indica que la mayoría de los textos están distantes, esto es el resultado de la bolsa de palabras discreta que se enfoca en modelar las palabras y no el significado de las mismas.</p>
<div id="cell-fig-text-repr-similitud-bow" class="cell" data-execution_count="14">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>sns.displot(sim.data)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-text-repr-similitud-bow" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-text-repr-similitud-bow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="05RepresentacionTexto_files/figure-html/fig-text-repr-similitud-bow-output-1.png" width="471" height="470" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-text-repr-similitud-bow-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;5.3: Histograma de la similitud
</figcaption>
</figure>
</div>
</div>
</div>
</section>
</section>
<section id="bolsa-de-palabras-densa" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="bolsa-de-palabras-densa"><span class="header-section-number">5.2</span> Bolsa de Palabras Densa</h2>
<p>La <a href="#fig-repr-texto-bolsa-densa" class="quarto-xref">Figura&nbsp;<span>5.4</span></a> muestra el procedimiento que se sigue para representar un texto en una bolsa de palabras dispersa. En primer lugar la bolsa de palabras densa considera que los vectores asociados a los términos se encuentra pre-entrenados y en general no es factible entrenarlos en el momento, esto por el tiempo que lleva estimar estos vectores.</p>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div id="fig-repr-texto-bolsa-densa" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-repr-texto-bolsa-densa-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div>
<pre class="mermaid mermaid-js" data-label="fig-repr-texto-bolsa-densa">flowchart LR
    Terminos([Texto\n Segmentado]) -- Pre-entrenados --&gt;  A[Asociación]
    A --&gt; Repr([Representación])
</pre>
</div>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-repr-texto-bolsa-densa-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;5.4: Diagrama Bolsa de Palabras Densa
</figcaption>
</figure>
</div>
</div>
</div>
<p>El texto se representa como el vector <span class="math inline">\(\mathbf u\)</span> que se calcula usando la <a href="#eq-bolsa-densas" class="quarto-xref">Ecuación&nbsp;<span>5.2</span></a> donde se observa que es la suma de los vectores asociados a cada término más un coeficiente <span class="math inline">\(\mathbf{w_0}\)</span>. En particular el coeficiente <span class="math inline">\(\mathbf{w_0} \in \mathbb R^{M}\)</span> no se encuentra en todas las representaciones densas, pero en la representación que se usará contiene este vector, <span class="math inline">\(M\)</span> es la dimensión de la representación densa.</p>
<p><span id="eq-bolsa-densas"><span class="math display">\[
\mathbf u = \sum_t \mathbf{u_t} + \mathbf{w_0}.
\tag{5.2}\]</span></span></p>
<p>En vector <span class="math inline">\(\mathbf {u_t}\)</span> está asociado al término <span class="math inline">\(t\)</span>, en particular este vector en la representación densa que se describirá está definido en términos de una bolsa de palabras dispersa (<a href="#eq-bolsa-palabras" class="quarto-xref">Ecuación&nbsp;<span>5.1</span></a>) como se puede observar en la <a href="#eq-bolsa-densa-ut" class="quarto-xref">Ecuación&nbsp;<span>5.3</span></a></p>
<p><span id="eq-bolsa-densa-ut"><span class="math display">\[
\mathbf{u_t} = \frac{\mathbf W \mathbf {v_t}}{\lVert \sum_t \mathbf{v_t} \rVert},
\tag{5.3}\]</span></span></p>
<p>donde <span class="math inline">\(\mathbf W \in \mathbb R^{M \times d}\)</span> es la matriz que hace la proyección de la representación dispersa a la representación densa, se puede observar esa operación está normalizada con la norma Euclideana de la representación dispersa.</p>
<p>Combinando las <a href="#eq-bolsa-densas" class="quarto-xref">Ecuación&nbsp;<span>5.2</span></a> y <a href="#eq-bolsa-densa-ut" class="quarto-xref">Ecuación&nbsp;<span>5.3</span></a> queda la</p>
<p><span class="math display">\[
\begin{split}
\mathbf{u_t} &amp;= \sum_t \frac{\mathbf W \mathbf {v_t}}{\lVert \sum_t \mathbf{v_t} \rVert} + \mathbf{w_0} \\
&amp;= \mathbf W \frac{\sum_t \mathbf {v_t}}{\lVert \sum_t \mathbf{v_t} \rVert} + \mathbf{w_0},
\end{split}
\]</span></p>
<p>donde se puede observar la representación dispersa (<a href="#eq-bolsa-palabras" class="quarto-xref">Ecuación&nbsp;<span>5.1</span></a>), i.e., <span class="math inline">\(\frac{\sum_t \mathbf {v_t}}{\lVert \sum_t \mathbf{v_t} \rVert}\)</span> lo cual resulta en la <a href="#eq-bolsa-densa-texto" class="quarto-xref">Ecuación&nbsp;<span>5.4</span></a></p>
<p><span id="eq-bolsa-densa-texto"><span class="math display">\[
\mathbf u = \mathbf W \mathbf x + \mathbf{w_0},
\tag{5.4}\]</span></span></p>
<p>que representa un texto en el vector <span class="math inline">\(\mathbf u \in \mathbb R^M.\)</span></p>
<p>Para algunas representaciones densas, las componentes de la matriz de transformación <span class="math inline">\(\mathcal W\)</span> están asociadas a conceptos, en el caso que se analiza estas están asociadas a palabras claves o emojis.</p>
<section id="ejemplos" class="level3" data-number="5.2.1">
<h3 data-number="5.2.1" class="anchored" data-anchor-id="ejemplos"><span class="header-section-number">5.2.1</span> Ejemplos</h3>
<p>Continuando con los ejemplos presentados para la bolsa dispersa (<a href="#sec-bolsa-dispersa-ejemplos" class="quarto-xref"><span>Sección 5.1.2</span></a>) en esta sección se hace el análisis con la representación de palabras densa. El primer paso es inicializar la clase que contiene las representaciones densas, esto se hace con la siguiente instrucción.</p>
<div id="feff6f37" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>dense <span class="op">=</span> DenseBoW(lang<span class="op">=</span><span class="st">'es'</span>,</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>                 voc_size_exponent<span class="op">=</span><span class="dv">15</span>,</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>                 emoji<span class="op">=</span><span class="va">False</span>, keyword<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>                 distance_hyperplane<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>                 dataset<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Para representar un texto en el espacio vectorial denso se utiliza el método <code>transform</code>, por ejemplo la siguiente instrucción representa el texto <em>Es un placer estar platicando con ustedes.</em> Solo se visualizan los valores de las primeras tres componentes.</p>
<div id="df5742af" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>txt1 <span class="op">=</span> <span class="st">'Es un placer estar platicando con ustedes.'</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>dense.transform([txt1])[<span class="dv">0</span>, :<span class="dv">3</span>]</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="16">
<pre><code>array([-0.0042934 , -0.00429635, -0.00515905])</code></pre>
</div>
</div>
<p>Lo primero que se observa es que los valores son negativos, a diferencia del caso disperso donde todos los valores son positivos. En este tipo de representación cada componente está asociada a una palabra las cuales se pueden conocer en el atributo <code>names</code>. El siguiente código muestra las tres primeras palabras asociadas al ejemplo anterior.</p>
<div id="10126283" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>dense.names[:<span class="dv">3</span>]</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>['semanas', 'cuatro', 'piensa']</code></pre>
</div>
</div>
<p>Siguiente la idea de utilizar una nube de palabras para visualizar el vector que representa el texto modelado, La <a href="#fig-repr-texto-nube-densa" class="quarto-xref">Figura&nbsp;<span>5.5</span></a> muestra las nubes de palabras generada con las características y sus respectivos valores del texto <em>Es un placer estar platicando con ustedes.</em> Durante la generación de la nube de palabras se decidió representar genera una nube de palabras con las palabras con coeficiente negativo más significativo y aquellas con los coeficientes positivos más significativos. Se puede observar que las palabras positivas contienen componentes que están relacionados al enunciado, pero al mismo tiempo leyendo los términos positivos es complicado construir el texto representado. Adicionalmente las términos negativos que se observan en la nube de palabras en su mayoría son hashtags que tiene muy poca relación al texto representado.</p>
<div id="cell-fig-repr-texto-nube-densa" class="cell" data-execution_count="18">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>values <span class="op">=</span> dense.transform([txt1])</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>names <span class="op">=</span> dense.names</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>tokens_pos <span class="op">=</span> {names[<span class="bu">id</span>]: v <span class="cf">for</span> <span class="bu">id</span>, v <span class="kw">in</span> <span class="bu">enumerate</span>(values[<span class="dv">0</span>]) <span class="cf">if</span> v <span class="op">&gt;</span> <span class="dv">0</span>}</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>tokens_neg <span class="op">=</span> {names[<span class="bu">id</span>]: v <span class="op">*</span> <span class="op">-</span><span class="dv">1</span> <span class="cf">for</span> <span class="bu">id</span>, v <span class="kw">in</span> <span class="bu">enumerate</span>(values[<span class="dv">0</span>]) <span class="cf">if</span> v <span class="op">&lt;</span> <span class="dv">0</span>}</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>word_pos <span class="op">=</span> WordCloud().generate_from_frequencies(tokens_pos)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>word_neg <span class="op">=</span> WordCloud().generate_from_frequencies(tokens_neg)</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> cloud, ax, title <span class="kw">in</span> <span class="bu">zip</span>([word_neg, word_pos],</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>                     [ax1, ax2],</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>                     [<span class="st">'Negativas'</span>, </span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>                      <span class="st">'Positivas'</span>]):</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a>    ax.imshow(cloud, interpolation<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a>    ax.grid(<span class="va">False</span>)</span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>    ax.tick_params(left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a>                   labelbottom<span class="op">=</span><span class="va">False</span>, bottom<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>    ax.set_title(title)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-repr-texto-nube-densa" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-repr-texto-nube-densa-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="05RepresentacionTexto_files/figure-html/fig-repr-texto-nube-densa-output-1.png" width="540" height="157" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-repr-texto-nube-densa-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;5.5: Nube de características para el texto <em>Es un placer estar platicando con ustedes.</em>
</figcaption>
</figure>
</div>
</div>
</div>
<p>Esta representación también permite comparación de similitud entre textos, en el siguiente ejemplo se calcula la similitud entre el texto <em>Es un placer estar platicando con ustedes.</em> y los textos <em>La lluvia genera un caos en la ciudad.</em> y <em>Estoy dando una platica en Morelia.</em> tal y como se hizo para la representación dispersa. Se puede observar que existe una mayor similitud entre los textos que contienen el concepto <strong>plática</strong>, lo cual es equivalente a lo que se observó en el ejemplo con bolsa de palabras discretas, pero los valores son significativamente mayores que en ese caso.</p>
<div id="24d526d4" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>txt1 <span class="op">=</span> <span class="st">'Es un placer estar platicando con ustedes.'</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>txt2 <span class="op">=</span> <span class="st">'La lluvia genera un caos en la ciudad.'</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>txt3 <span class="op">=</span> <span class="st">'Estoy dando una platica en Morelia.'</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> dense.transform([txt1, txt2, txt3])</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>np.dot(X[<span class="dv">0</span>], X[<span class="dv">1</span>]), np.dot(X[<span class="dv">0</span>], X[<span class="dv">2</span>])</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="19">
<pre><code>(0.7728943423183761, 0.8721107462230386)</code></pre>
</div>
</div>
<p>Los valores de similitud entre los enunciados anteriores, se puede visualizar en una nube de palabras, utilizando solo las características positivas. La <a href="#fig-repr-texto-nube-densa-comp" class="quarto-xref">Figura&nbsp;<span>5.6</span></a> muestra las nubes de palabras generadas, en ellas es complicado comprender la razón por la cual la frases que tiene el concepto <em>plática</em> están más cercanas, es probable que la cola de la distribución, es decir, las palabras menos significativas son las que acercan las dos oraciones.</p>
<div id="cell-fig-repr-texto-nube-densa-comp" class="cell" data-execution_count="20">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>values <span class="op">=</span> dense.transform([txt1, txt2, txt3])</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>names <span class="op">=</span> dense.names</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>tokens_pos <span class="op">=</span> {names[<span class="bu">id</span>]: v <span class="cf">for</span> <span class="bu">id</span>, v <span class="kw">in</span> <span class="bu">enumerate</span>(values[<span class="dv">0</span>]) <span class="cf">if</span> v <span class="op">&gt;</span> <span class="dv">0</span>}</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>tokens_neg <span class="op">=</span> {names[<span class="bu">id</span>]: v <span class="cf">for</span> <span class="bu">id</span>, v <span class="kw">in</span> <span class="bu">enumerate</span>(values[<span class="dv">1</span>]) <span class="cf">if</span> v <span class="op">&gt;</span> <span class="dv">0</span>}</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>tokens_otro <span class="op">=</span> {names[<span class="bu">id</span>]: v <span class="cf">for</span> <span class="bu">id</span>, v <span class="kw">in</span> <span class="bu">enumerate</span>(values[<span class="dv">2</span>]) <span class="cf">if</span> v <span class="op">&gt;</span> <span class="dv">0</span>}</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>word_pos <span class="op">=</span> WordCloud().generate_from_frequencies(tokens_pos)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>word_neg <span class="op">=</span> WordCloud().generate_from_frequencies(tokens_neg)</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>word_otro <span class="op">=</span> WordCloud().generate_from_frequencies(tokens_otro)</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2, ax3) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>)</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> cloud, ax, title <span class="kw">in</span> <span class="bu">zip</span>([word_pos, word_neg, word_otro],</span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a>                     [ax1, ax2, ax3],</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>                     [<span class="st">'Es un ... ustedes.'</span>, </span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>                      <span class="st">'La lluvia ... ciudad.'</span>,</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>                      <span class="st">'Estoy ... Morelia.'</span>]):</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>    ax.imshow(cloud, interpolation<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>    ax.grid(<span class="va">False</span>)</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>    ax.tick_params(left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>                   labelbottom<span class="op">=</span><span class="va">False</span>, bottom<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>    ax.set_title(title)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-repr-texto-nube-densa-comp" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-repr-texto-nube-densa-comp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="05RepresentacionTexto_files/figure-html/fig-repr-texto-nube-densa-comp-output-1.png" width="540" height="115" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-repr-texto-nube-densa-comp-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;5.6: Nube de características positivas.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Al igual que en el caso disperso se puede calcular la distribución de similitud. Las siguientes instrucciones calcula la similitud coseno entre todos los ejemplos del conjunto de entrenamiento (<span class="math inline">\(\mathcal T\)</span>).</p>
<div id="57e495f2" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> dense.transform(D)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>sim <span class="op">=</span> np.dot(X, X.T)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>La <a href="#fig-text-repr-similitud-dense" class="quarto-xref">Figura&nbsp;<span>5.7</span></a> muestra el histograma de las similitudes calculada mediante la bolsa densa. Aquí se puede observar que la gran mayoría de los ejemplos tiene una similitud mayor y tiene una desviación estándar mayor que la vista en la <a href="#fig-text-repr-similitud-bow" class="quarto-xref">Figura&nbsp;<span>5.3</span></a>.</p>
<div id="cell-fig-text-repr-similitud-dense" class="cell" data-execution_count="22">
<details class="code-fold">
<summary>Código</summary>
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>sns.displot(sim.flatten())</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div id="fig-text-repr-similitud-dense" class="quarto-figure quarto-figure-center quarto-float anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-text-repr-similitud-dense-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="05RepresentacionTexto_files/figure-html/fig-text-repr-similitud-dense-output-1.png" width="471" height="470" class="figure-img">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-text-repr-similitud-dense-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figura&nbsp;5.7: Histograma de la similitud usando bolsa de palabras densas
</figcaption>
</figure>
</div>
</div>
</div>


<!-- -->

<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-Salton1973" class="csl-entry" role="listitem">
Salton, Gerard, y Chungshu S. Yang. 1973. <span>«On the specification of term values in automatic indexing»</span>. <em>Journal of Documentation</em> 29 (abril): 351-72. <a href="https://doi.org/10.1108/EB026562">https://doi.org/10.1108/EB026562</a>.
</div>
<div id="ref-Jones1972" class="csl-entry" role="listitem">
Sparck Jones, Karen. 1972. <span>«A statistical interpretation of term specificity and its application in retrieval»</span>. <em>Journal of Documentation</em> 28: 11-21. <a href="https://doi.org/10.1108/EB026526">https://doi.org/10.1108/EB026526</a>.
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../capitulos/04FundamentosCT.html" class="pagination-link" aria-label="Fundamentos de Clasificación de Texto">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Fundamentos de Clasificación de Texto</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../capitulos/06ClasificacionTexto.html" class="pagination-link" aria-label="Clasificación de Texto">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Clasificación de Texto</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Ejecutar el código</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb27" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Representación de Texto</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>El **objetivo** de la unidad es </span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a><span class="fu">## Paquetes usados {.unnumbered}</span></span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> EvoMSA <span class="im">import</span> BoW,<span class="op">\</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>                   DenseBoW</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> microtc.utils <span class="im">import</span> tweet_iterator</span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> wordcloud <span class="im">import</span> WordCloud                            </span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pylab <span class="im">as</span> plt</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> Markdown</span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>sns.set_style(<span class="st">'whitegrid'</span>)</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-31"><a href="#cb27-31" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb27-32"><a href="#cb27-32" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb27-33"><a href="#cb27-33" aria-hidden="true" tabindex="-1"></a><span class="co">#| output: false</span></span>
<span id="cb27-34"><a href="#cb27-34" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> os.path <span class="im">import</span> isfile, isdir</span>
<span id="cb27-35"><a href="#cb27-35" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> EvoMSA.utils <span class="im">import</span> Download</span>
<span id="cb27-36"><a href="#cb27-36" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> EvoMSA <span class="im">import</span> utils</span>
<span id="cb27-37"><a href="#cb27-37" aria-hidden="true" tabindex="-1"></a>utils.USE_TQDM <span class="op">=</span> <span class="va">False</span></span>
<span id="cb27-38"><a href="#cb27-38" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> isfile(<span class="st">'delitos.zip'</span>):</span>
<span id="cb27-39"><a href="#cb27-39" aria-hidden="true" tabindex="-1"></a>    Download(<span class="st">'https://github.com/INGEOTEC/Delitos/releases/download/Datos/delitos.zip'</span>,</span>
<span id="cb27-40"><a href="#cb27-40" aria-hidden="true" tabindex="-1"></a>             <span class="st">'delitos.zip'</span>)</span>
<span id="cb27-41"><a href="#cb27-41" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> <span class="kw">not</span> isdir(<span class="st">'delitos'</span>):</span>
<span id="cb27-42"><a href="#cb27-42" aria-hidden="true" tabindex="-1"></a>    <span class="op">!</span>unzip <span class="op">-</span>Pingeotec delitos.<span class="bu">zip</span></span>
<span id="cb27-43"><a href="#cb27-43" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-44"><a href="#cb27-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-45"><a href="#cb27-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-46"><a href="#cb27-46" aria-hidden="true" tabindex="-1"></a>::: {.content-visible when-format="html"}</span>
<span id="cb27-47"><a href="#cb27-47" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb27-48"><a href="#cb27-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-49"><a href="#cb27-49" aria-hidden="true" tabindex="-1"></a>**Video explicando la unidad**</span>
<span id="cb27-50"><a href="#cb27-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-51"><a href="#cb27-51" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb27-52"><a href="#cb27-52" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb27-53"><a href="#cb27-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-54"><a href="#cb27-54" aria-hidden="true" tabindex="-1"></a><span class="fu">## Bolsa de Palabras Dispersa </span></span>
<span id="cb27-55"><a href="#cb27-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-56"><a href="#cb27-56" aria-hidden="true" tabindex="-1"></a>La idea de una bolsa de palabras discretas es que después de haber normalizado y segmentado el texto (@sec-manejando-texto), cada token $t$ sea asociado a un vector único $\mathbf{v_t} \in \mathbb R^d$ donde la $i$-ésima componente, i.e., $\mathbf{v_t}_i$, es diferente de cero y $\forall_{j \neq i} \mathbf{v_t}_j=0$. Es decir la $i$-ésima componente está asociada al token $t$, se podría pensar que si el vocabulario está ordenado de alguna manera, entonces el token $t$ está en la posición $i$. Por otro lado el valor que contiene la componente se usa para representar alguna característica del token. </span>
<span id="cb27-57"><a href="#cb27-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-58"><a href="#cb27-58" aria-hidden="true" tabindex="-1"></a>El conjunto de vectores $\mathbf v$ corresponde al vocabulario, teniendo $d$ diferentes token en el mismo y por definición $\forall_{i \neq j} \mathbf{v_i} \cdot \mathbf{v_j} = 0$, donde $\mathbf{v_i} \in \mathbb R^d$, $\mathbf{v_j} \in \mathbb R^d$, y $(\cdot)$ es el producto punto. Cabe mencionar que cualquier token fuera del vocabulario es descartado. </span>
<span id="cb27-59"><a href="#cb27-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-60"><a href="#cb27-60" aria-hidden="true" tabindex="-1"></a>Usando esta notación, un texto $x$ está representado por una secuencia de términos, i.e., $(t_1, t_2, \ldots)$; la secuencia puede tener repeticiones es decir, $t_j = t_k$. Utilizando la característica de que cada token está asociado a un vector $\mathbf v$, se transforma la secuencia de términos a una secuencia de vectores (manteniendo las repeticiones), i.e., $(\mathbf{v_{t_1}}, \mathbf{v_{t_2}}, \ldots)$. Finalmente, el texto $x$ se representa como:</span>
<span id="cb27-61"><a href="#cb27-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-62"><a href="#cb27-62" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb27-63"><a href="#cb27-63" aria-hidden="true" tabindex="-1"></a>\mathbf x = \frac{\sum_t \mathbf{v_t}}{\lVert \sum_t \mathbf{v_t} \rVert},</span>
<span id="cb27-64"><a href="#cb27-64" aria-hidden="true" tabindex="-1"></a>$$ {#eq-bolsa-palabras}</span>
<span id="cb27-65"><a href="#cb27-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-66"><a href="#cb27-66" aria-hidden="true" tabindex="-1"></a>donde la suma se hace para todos los elementos de la secuencia, $\mathbf x \in \mathbb R^d$, y $\lVert \mathbf w \rVert$ es la norma Euclideana del vector $\mathbf w.$</span>
<span id="cb27-67"><a href="#cb27-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-70"><a href="#cb27-70" aria-hidden="true" tabindex="-1"></a><span class="in">```{mermaid}</span></span>
<span id="cb27-71"><a href="#cb27-71" aria-hidden="true" tabindex="-1"></a><span class="in">%%| echo: false</span></span>
<span id="cb27-72"><a href="#cb27-72" aria-hidden="true" tabindex="-1"></a><span class="in">%%| fig-cap: Diagrama Bolsa de Palabras Dispersa</span></span>
<span id="cb27-73"><a href="#cb27-73" aria-hidden="true" tabindex="-1"></a><span class="in">%%| label: fig-repr-texto-bolsa-dispersa</span></span>
<span id="cb27-74"><a href="#cb27-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-75"><a href="#cb27-75" aria-hidden="true" tabindex="-1"></a><span class="in">flowchart LR</span></span>
<span id="cb27-76"><a href="#cb27-76" aria-hidden="true" tabindex="-1"></a><span class="in">    Terminos([Texto\n Segmentado]) -- Pre-entrenados --&gt;  A[Asociación]</span></span>
<span id="cb27-77"><a href="#cb27-77" aria-hidden="true" tabindex="-1"></a><span class="in">    Terminos --&gt; Entrenamiento[Estimación\n de Pesos]</span></span>
<span id="cb27-78"><a href="#cb27-78" aria-hidden="true" tabindex="-1"></a><span class="in">    Corpus([Corpus]) -.-&gt; Entrenamiento</span></span>
<span id="cb27-79"><a href="#cb27-79" aria-hidden="true" tabindex="-1"></a><span class="in">    Entrenamiento --&gt; A</span></span>
<span id="cb27-80"><a href="#cb27-80" aria-hidden="true" tabindex="-1"></a><span class="in">    A --&gt; Repr([Representación])</span></span>
<span id="cb27-81"><a href="#cb27-81" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-82"><a href="#cb27-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-83"><a href="#cb27-83" aria-hidden="true" tabindex="-1"></a>Antes de iniciar la descripción detallada del proceso de representación utilizando una bolsa de palabras dispersas, es conveniente ilustrar este proceso mediante la @fig-repr-texto-bolsa-dispersa. El **texto segmentado** es el resultado del proceso ilustrado en @fig-pre-procesamiento. El texto segmentado puede seguir dos caminos, en la parte superior se encuentra el caso cuando los pesos han sido identificados previamente y en la parte inferior es el procedimiento cuando los pesos se estiman mediante un corpus específico que normalmente es un conjunto de entrenamiento. </span>
<span id="cb27-84"><a href="#cb27-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-85"><a href="#cb27-85" aria-hidden="true" tabindex="-1"></a><span class="fu">### Pesado de Términos </span></span>
<span id="cb27-86"><a href="#cb27-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-87"><a href="#cb27-87" aria-hidden="true" tabindex="-1"></a>Como se había mencionado el valor que tiene la componente $i$-ésima del vector $\mathbf{v_t}_i$ corresponde a una característica del término asociado, este procedimiento se le conoce como el **esquema de pesado**. Por ejemplo, si el valor es $1$ (i.e., $\mathbf{v_{t_i}} = 1$) entonces el valor está indicando solo la presencia del término, este es el caso más simple. Considerando la @eq-bolsa-palabras se observa que el resultado, $\mathbf x$, cuenta las repeticiones de cada término, por esta característica a este esquema se le conoce como **frecuencia de términos** (*term frequency (TF)*). </span>
<span id="cb27-88"><a href="#cb27-88" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-89"><a href="#cb27-89" aria-hidden="true" tabindex="-1"></a>Una medida que complementa la información que tiene la frecuencia de términos es el inverso de la frecuencia del término (*Inverse Document Frequency (IDF)*) en la colección, esta medida propuesta por @Jones1972 se usa en un método de pesado descrito por @Salton1973 el cual es conocido como **TFIDF**. Este método de pesado propone el considerar el producto de la frecuencia del término y el inverso de la frecuencia del término (*Inverse Document Frequency (IDF)* ) en la colección como el peso del término.</span>
<span id="cb27-90"><a href="#cb27-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-91"><a href="#cb27-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-92"><a href="#cb27-92" aria-hidden="true" tabindex="-1"></a><span class="fu">### Ejemplos {#sec-bolsa-dispersa-ejemplos}</span></span>
<span id="cb27-93"><a href="#cb27-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-96"><a href="#cb27-96" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb27-97"><a href="#cb27-97" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb27-98"><a href="#cb27-98" aria-hidden="true" tabindex="-1"></a>bow <span class="op">=</span> BoW(lang<span class="op">=</span><span class="st">'es'</span>)</span>
<span id="cb27-99"><a href="#cb27-99" aria-hidden="true" tabindex="-1"></a>tm <span class="op">=</span> bow.bow</span>
<span id="cb27-100"><a href="#cb27-100" aria-hidden="true" tabindex="-1"></a>vec <span class="op">=</span> tm[<span class="st">'Buen día'</span>]</span>
<span id="cb27-101"><a href="#cb27-101" aria-hidden="true" tabindex="-1"></a>key_f <span class="op">=</span> Markdown(<span class="ss">f'$</span><span class="sc">{</span>vec[<span class="dv">0</span>][<span class="dv">0</span>]<span class="sc">}</span><span class="ss">$'</span>)</span>
<span id="cb27-102"><a href="#cb27-102" aria-hidden="true" tabindex="-1"></a>key_txt <span class="op">=</span> Markdown(<span class="ss">f'*</span><span class="sc">{</span>tm<span class="sc">.</span>id2token[vec[<span class="dv">0</span>][<span class="dv">0</span>]]<span class="sc">}</span><span class="ss">*'</span>)</span>
<span id="cb27-103"><a href="#cb27-103" aria-hidden="true" tabindex="-1"></a>idf_f <span class="op">=</span> Markdown(<span class="ss">f'$</span><span class="sc">{</span>vec[<span class="dv">0</span>][<span class="dv">1</span>]<span class="sc">:0.4f}</span><span class="ss">$'</span>)</span>
<span id="cb27-104"><a href="#cb27-104" aria-hidden="true" tabindex="-1"></a>len_f <span class="op">=</span> Markdown(<span class="ss">f'$</span><span class="sc">{</span><span class="bu">len</span>(vec)<span class="sc">}</span><span class="ss">$'</span>)</span>
<span id="cb27-105"><a href="#cb27-105" aria-hidden="true" tabindex="-1"></a>voc_f <span class="op">=</span> Markdown(<span class="ss">f'$</span><span class="sc">{</span><span class="bu">len</span>(bow.names)<span class="sc">}</span><span class="ss">$'</span>)</span>
<span id="cb27-106"><a href="#cb27-106" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-107"><a href="#cb27-107" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-108"><a href="#cb27-108" aria-hidden="true" tabindex="-1"></a>En los siguientes ejemplos se usa una bolsa de palabras con un pesado TFIDF pre-entrenada, los datos de esta bolsa de palabras se encuentra en el atributo <span class="in">`BoW.bow`</span>. El tamaño del vocabulario es <span class="in">`{python} voc_f`</span>, que está compuesto por palabras, gramas de palabras y caracteres. En el siguiente ejemplo se muestran los primeros tres gramas con sus respectivos valores TFIDF de la frase *Buen día*. Se puede observar que el <span class="in">`tm`</span> regresa una lista de pares, donde la primera parte es el identificador del término, e.g., <span class="in">`{python} key_f`</span> y el segundo es el valor TFIDF, e.g., <span class="in">`{python} idf_f`</span>. La lista tiene un tamaño de <span class="in">`{python} len_f`</span> elementos, el resto de los  <span class="in">`{python} voc_f`</span> componentes son cero dado que no se encuentran en el texto representado. </span>
<span id="cb27-109"><a href="#cb27-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-112"><a href="#cb27-112" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb27-113"><a href="#cb27-113" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb27-114"><a href="#cb27-114" aria-hidden="true" tabindex="-1"></a>bow <span class="op">=</span> BoW(lang<span class="op">=</span><span class="st">'es'</span>)</span>
<span id="cb27-115"><a href="#cb27-115" aria-hidden="true" tabindex="-1"></a>tm <span class="op">=</span> bow.bow</span>
<span id="cb27-116"><a href="#cb27-116" aria-hidden="true" tabindex="-1"></a>vec <span class="op">=</span> tm[<span class="st">'Buen día'</span>]</span>
<span id="cb27-117"><a href="#cb27-117" aria-hidden="true" tabindex="-1"></a>vec[:<span class="dv">3</span>]</span>
<span id="cb27-118"><a href="#cb27-118" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-119"><a href="#cb27-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-120"><a href="#cb27-120" aria-hidden="true" tabindex="-1"></a>El uso del identificador del término se puede reemplazar por el término para poder visualizar mejor la representación del texto en el espacio vectorial. El diccionario que se encuentra en <span class="in">`BoW.names`</span> hace la relación identificador a término. Se puede ver que el primer elemento del vector es el bigrama *buen~dia*, seguido por *buen* y el tercer término es *dia*. Los siguientes términos que no se muestran corresponden a gramas de caracteres. El valor TFIDF no indica la importancia del término, mientras mayor sea el valor, se considera más importante de acuerdo al TFIDF. En este ejemplo el bigrama tiene más importancia que las palabras y la palabra *buen* es más significativa que *dia*.</span>
<span id="cb27-121"><a href="#cb27-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-124"><a href="#cb27-124" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb27-125"><a href="#cb27-125" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb27-126"><a href="#cb27-126" aria-hidden="true" tabindex="-1"></a>[(bow.names[k], v)</span>
<span id="cb27-127"><a href="#cb27-127" aria-hidden="true" tabindex="-1"></a> <span class="cf">for</span> k, v <span class="kw">in</span> vec[:<span class="dv">3</span>]]</span>
<span id="cb27-128"><a href="#cb27-128" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-129"><a href="#cb27-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-130"><a href="#cb27-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-133"><a href="#cb27-133" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb27-134"><a href="#cb27-134" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb27-135"><a href="#cb27-135" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="st">'Buen día colegas'</span></span>
<span id="cb27-136"><a href="#cb27-136" aria-hidden="true" tabindex="-1"></a>vec2 <span class="op">=</span> tm[txt]</span>
<span id="cb27-137"><a href="#cb27-137" aria-hidden="true" tabindex="-1"></a>idf2_f <span class="op">=</span> Markdown(<span class="ss">f'$</span><span class="sc">{</span>vec2[<span class="dv">0</span>][<span class="dv">1</span>]<span class="sc">:0.4f}</span><span class="ss">$'</span>)</span>
<span id="cb27-138"><a href="#cb27-138" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-139"><a href="#cb27-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-140"><a href="#cb27-140" aria-hidden="true" tabindex="-1"></a>Con el objetivo de ilustrar una heurística que ha dado buenos resultados en el siguiente ejemplo se presentan las primeras cuatro componentes del texto *Buen día colegas*. Se puede observar como los valores de IDF de los términos comunes cambiaron, por ejemplo para el caso de `{python} key_txt` cambio de `{python} idf_f` a `{python} idf2_f`. Este es el resultado de que los valores están normalizados tal como se muestra en la @eq-bolsa-palabras. Por otro lado, se observa que ahora el término más significativo es la palabra *colegas*. </span>
<span id="cb27-141"><a href="#cb27-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-144"><a href="#cb27-144" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb27-145"><a href="#cb27-145" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb27-146"><a href="#cb27-146" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="st">'Buen día colegas'</span></span>
<span id="cb27-147"><a href="#cb27-147" aria-hidden="true" tabindex="-1"></a>[(tm.id2token[k], v)</span>
<span id="cb27-148"><a href="#cb27-148" aria-hidden="true" tabindex="-1"></a> <span class="cf">for</span> k, v <span class="kw">in</span> tm[txt][:<span class="dv">4</span>]]</span>
<span id="cb27-149"><a href="#cb27-149" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-150"><a href="#cb27-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-151"><a href="#cb27-151" aria-hidden="true" tabindex="-1"></a>Una manera de visualizar la representación es creando una nube de palabras de los términos, donde el tamaño del termino corresponde al valor TFIDF. En la @fig-repr-texto-nube muestra la nube de palabras generada con los términos y sus respectivos valores IDF del texto *Es un placer estar platicando con ustedes.*</span>
<span id="cb27-152"><a href="#cb27-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-155"><a href="#cb27-155" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb27-156"><a href="#cb27-156" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb27-157"><a href="#cb27-157" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Nube de términos</span></span>
<span id="cb27-158"><a href="#cb27-158" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-repr-texto-nube</span></span>
<span id="cb27-159"><a href="#cb27-159" aria-hidden="true" tabindex="-1"></a>txt <span class="op">=</span> <span class="st">'Es un placer estar platicando con ustedes.'</span></span>
<span id="cb27-160"><a href="#cb27-160" aria-hidden="true" tabindex="-1"></a>tokens <span class="op">=</span> {tm.id2token[<span class="bu">id</span>]: v <span class="cf">for</span> <span class="bu">id</span>, v <span class="kw">in</span> tm[txt]}</span>
<span id="cb27-161"><a href="#cb27-161" aria-hidden="true" tabindex="-1"></a>word_cloud <span class="op">=</span> WordCloud().generate_from_frequencies(tokens)</span>
<span id="cb27-162"><a href="#cb27-162" aria-hidden="true" tabindex="-1"></a>plt.imshow(word_cloud, interpolation<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb27-163"><a href="#cb27-163" aria-hidden="true" tabindex="-1"></a>plt.grid(<span class="va">False</span>)</span>
<span id="cb27-164"><a href="#cb27-164" aria-hidden="true" tabindex="-1"></a>plt.tick_params(left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb27-165"><a href="#cb27-165" aria-hidden="true" tabindex="-1"></a>                labelbottom<span class="op">=</span><span class="va">False</span>, bottom<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb27-166"><a href="#cb27-166" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-167"><a href="#cb27-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-168"><a href="#cb27-168" aria-hidden="true" tabindex="-1"></a>El texto se representa en un espacio vectorial, entonces es posible comparar la similitud entre dos textos en esta representación, por ejemplo, en el siguiente ejemplo se compara la similitud coseno entre los textos *Es un placer estar platicando con ustedes.* y *La lluvia genera un caos en la ciudad.* El valor obtenido es cercano a cero indicando que estos textos no son similares. </span>
<span id="cb27-169"><a href="#cb27-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-172"><a href="#cb27-172" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb27-173"><a href="#cb27-173" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb27-174"><a href="#cb27-174" aria-hidden="true" tabindex="-1"></a>txt1 <span class="op">=</span> <span class="st">'Es un placer estar platicando con ustedes.'</span></span>
<span id="cb27-175"><a href="#cb27-175" aria-hidden="true" tabindex="-1"></a>txt2 <span class="op">=</span> <span class="st">'La lluvia genera un caos en la ciudad.'</span></span>
<span id="cb27-176"><a href="#cb27-176" aria-hidden="true" tabindex="-1"></a>vec1 <span class="op">=</span> tm[txt1]</span>
<span id="cb27-177"><a href="#cb27-177" aria-hidden="true" tabindex="-1"></a>vec2 <span class="op">=</span> tm[txt2]</span>
<span id="cb27-178"><a href="#cb27-178" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> {k: v <span class="cf">for</span> k, v <span class="kw">in</span> vec1}</span>
<span id="cb27-179"><a href="#cb27-179" aria-hidden="true" tabindex="-1"></a>np.<span class="bu">sum</span>([f[k] <span class="op">*</span> v <span class="cf">for</span> k, v <span class="kw">in</span> vec2 <span class="cf">if</span> k <span class="kw">in</span> f])</span>
<span id="cb27-180"><a href="#cb27-180" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-181"><a href="#cb27-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-182"><a href="#cb27-182" aria-hidden="true" tabindex="-1"></a>Complementando el ejemplo anterior, en esta ocasión se comparan dos textos que comparten el concepto *plática*, estos son *Es un placer estar platicando con ustedes.* y *Estoy dando una platica en Morelia.* se puede observar que estos textos son más similares que los ejemplos anteriores. </span>
<span id="cb27-183"><a href="#cb27-183" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-186"><a href="#cb27-186" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb27-187"><a href="#cb27-187" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb27-188"><a href="#cb27-188" aria-hidden="true" tabindex="-1"></a>txt1 <span class="op">=</span> <span class="st">'Es un placer estar platicando con ustedes.'</span></span>
<span id="cb27-189"><a href="#cb27-189" aria-hidden="true" tabindex="-1"></a>txt2 <span class="op">=</span> <span class="st">'Estoy dando una platica en Morelia.'</span></span>
<span id="cb27-190"><a href="#cb27-190" aria-hidden="true" tabindex="-1"></a>vec1 <span class="op">=</span> tm[txt1]</span>
<span id="cb27-191"><a href="#cb27-191" aria-hidden="true" tabindex="-1"></a>vec2 <span class="op">=</span> tm[txt2]</span>
<span id="cb27-192"><a href="#cb27-192" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> {k: v <span class="cf">for</span> k, v <span class="kw">in</span> vec1}</span>
<span id="cb27-193"><a href="#cb27-193" aria-hidden="true" tabindex="-1"></a>np.<span class="bu">sum</span>([f[k] <span class="op">*</span> v <span class="cf">for</span> k, v <span class="kw">in</span> vec2 <span class="cf">if</span> k <span class="kw">in</span> f])</span>
<span id="cb27-194"><a href="#cb27-194" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-195"><a href="#cb27-195" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb27-196"><a href="#cb27-196" aria-hidden="true" tabindex="-1"></a> Habiendo realizado la similitud entre algunos textos lleva a preguntarse cómo será la distribución de similitud entre varios textos, para poder contestar esta pregunta, se utilizarán los datos de <span class="co">[</span><span class="ot">Delitos</span><span class="co">](https://ingeotec.github.io/Delitos)</span>, los cuales se guardan en la variable <span class="in">`D`</span> tal y como se en las siguientes instrucciones. </span>
<span id="cb27-197"><a href="#cb27-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-200"><a href="#cb27-200" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb27-201"><a href="#cb27-201" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb27-202"><a href="#cb27-202" aria-hidden="true" tabindex="-1"></a>fname <span class="op">=</span> <span class="st">'delitos/delitos_ingeotec_Es_train.json'</span></span>
<span id="cb27-203"><a href="#cb27-203" aria-hidden="true" tabindex="-1"></a>D <span class="op">=</span> <span class="bu">list</span>(tweet_iterator(fname))</span>
<span id="cb27-204"><a href="#cb27-204" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-205"><a href="#cb27-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-206"><a href="#cb27-206" aria-hidden="true" tabindex="-1"></a>El primer paso es representar todos los textos en el espacio vectorial de la bolsa de palabras, lo cual se logra con el método <span class="in">`BoW.transform`</span> (primera linea), el segundo paso es calcular la similitud entre todos los textos, como se muestra en la segunda linea. </span>
<span id="cb27-207"><a href="#cb27-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-210"><a href="#cb27-210" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb27-211"><a href="#cb27-211" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb27-212"><a href="#cb27-212" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> tm.transform(D)</span>
<span id="cb27-213"><a href="#cb27-213" aria-hidden="true" tabindex="-1"></a>sim <span class="op">=</span> np.dot(X, X.T)</span>
<span id="cb27-214"><a href="#cb27-214" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-215"><a href="#cb27-215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-216"><a href="#cb27-216" aria-hidden="true" tabindex="-1"></a>La distribución de similitud se muestra en la @fig-text-repr-similitud-bow se puede observar que las similitudes se encuentran concentradas cerca del cero, esto indica que la mayoría de los textos están distantes, esto es el resultado de la bolsa de palabras discreta que se enfoca en modelar las palabras y no el significado de las mismas. </span>
<span id="cb27-217"><a href="#cb27-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-218"><a href="#cb27-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-221"><a href="#cb27-221" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb27-222"><a href="#cb27-222" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb27-223"><a href="#cb27-223" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Histograma de la similitud</span></span>
<span id="cb27-224"><a href="#cb27-224" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-text-repr-similitud-bow</span></span>
<span id="cb27-225"><a href="#cb27-225" aria-hidden="true" tabindex="-1"></a>sns.displot(sim.data)</span>
<span id="cb27-226"><a href="#cb27-226" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-227"><a href="#cb27-227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-228"><a href="#cb27-228" aria-hidden="true" tabindex="-1"></a><span class="fu">## Bolsa de Palabras Densa </span></span>
<span id="cb27-229"><a href="#cb27-229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-230"><a href="#cb27-230" aria-hidden="true" tabindex="-1"></a>La @fig-repr-texto-bolsa-densa muestra el procedimiento que se sigue para representar un texto en una bolsa de palabras dispersa. En primer lugar la bolsa de palabras densa considera que los vectores asociados a los términos se encuentra pre-entrenados y en general no es factible entrenarlos en el momento, esto por el tiempo que lleva estimar estos vectores. </span>
<span id="cb27-231"><a href="#cb27-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-234"><a href="#cb27-234" aria-hidden="true" tabindex="-1"></a><span class="in">```{mermaid}</span></span>
<span id="cb27-235"><a href="#cb27-235" aria-hidden="true" tabindex="-1"></a><span class="in">%%| echo: false</span></span>
<span id="cb27-236"><a href="#cb27-236" aria-hidden="true" tabindex="-1"></a><span class="in">%%| fig-cap: Diagrama Bolsa de Palabras Densa</span></span>
<span id="cb27-237"><a href="#cb27-237" aria-hidden="true" tabindex="-1"></a><span class="in">%%| label: fig-repr-texto-bolsa-densa</span></span>
<span id="cb27-238"><a href="#cb27-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-239"><a href="#cb27-239" aria-hidden="true" tabindex="-1"></a><span class="in">flowchart LR</span></span>
<span id="cb27-240"><a href="#cb27-240" aria-hidden="true" tabindex="-1"></a><span class="in">    Terminos([Texto\n Segmentado]) -- Pre-entrenados --&gt;  A[Asociación]</span></span>
<span id="cb27-241"><a href="#cb27-241" aria-hidden="true" tabindex="-1"></a><span class="in">    A --&gt; Repr([Representación])</span></span>
<span id="cb27-242"><a href="#cb27-242" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-243"><a href="#cb27-243" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-244"><a href="#cb27-244" aria-hidden="true" tabindex="-1"></a>El texto se representa como el vector $\mathbf u$ que se calcula usando la @eq-bolsa-densas donde se observa que es la suma de los vectores asociados a cada término más un coeficiente $\mathbf{w_0}$. En particular el coeficiente $\mathbf{w_0} \in \mathbb R^{M}$ no se encuentra en todas las representaciones densas, pero en la representación que se usará contiene este vector, $M$ es la dimensión de la representación densa. </span>
<span id="cb27-245"><a href="#cb27-245" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-246"><a href="#cb27-246" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb27-247"><a href="#cb27-247" aria-hidden="true" tabindex="-1"></a>\mathbf u = \sum_t \mathbf{u_t} + \mathbf{w_0}.</span>
<span id="cb27-248"><a href="#cb27-248" aria-hidden="true" tabindex="-1"></a>$$ {#eq-bolsa-densas}</span>
<span id="cb27-249"><a href="#cb27-249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-250"><a href="#cb27-250" aria-hidden="true" tabindex="-1"></a>En vector $\mathbf {u_t}$ está asociado al término $t$, en particular este vector en la representación densa que se describirá está definido en términos de una bolsa de palabras dispersa (@eq-bolsa-palabras) como se puede observar en la @eq-bolsa-densa-ut</span>
<span id="cb27-251"><a href="#cb27-251" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-252"><a href="#cb27-252" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb27-253"><a href="#cb27-253" aria-hidden="true" tabindex="-1"></a>\mathbf{u_t} = \frac{\mathbf W \mathbf {v_t}}{\lVert \sum_t \mathbf{v_t} \rVert},</span>
<span id="cb27-254"><a href="#cb27-254" aria-hidden="true" tabindex="-1"></a>$$ {#eq-bolsa-densa-ut}</span>
<span id="cb27-255"><a href="#cb27-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-256"><a href="#cb27-256" aria-hidden="true" tabindex="-1"></a>donde $\mathbf W \in \mathbb R^{M \times d}$ es la matriz que hace la proyección de la representación dispersa a la representación densa, se puede observar esa operación está normalizada con la norma Euclideana de la representación dispersa. </span>
<span id="cb27-257"><a href="#cb27-257" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-258"><a href="#cb27-258" aria-hidden="true" tabindex="-1"></a>Combinando las @eq-bolsa-densas y @eq-bolsa-densa-ut queda la </span>
<span id="cb27-259"><a href="#cb27-259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-260"><a href="#cb27-260" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb27-261"><a href="#cb27-261" aria-hidden="true" tabindex="-1"></a>\begin{split}</span>
<span id="cb27-262"><a href="#cb27-262" aria-hidden="true" tabindex="-1"></a>\mathbf{u_t} &amp;= \sum_t \frac{\mathbf W \mathbf {v_t}}{\lVert \sum_t \mathbf{v_t} \rVert} + \mathbf{w_0} <span class="sc">\\</span></span>
<span id="cb27-263"><a href="#cb27-263" aria-hidden="true" tabindex="-1"></a>&amp;= \mathbf W \frac{\sum_t \mathbf {v_t}}{\lVert \sum_t \mathbf{v_t} \rVert} + \mathbf{w_0},</span>
<span id="cb27-264"><a href="#cb27-264" aria-hidden="true" tabindex="-1"></a>\end{split}</span>
<span id="cb27-265"><a href="#cb27-265" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb27-266"><a href="#cb27-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-267"><a href="#cb27-267" aria-hidden="true" tabindex="-1"></a>donde se puede observar la representación dispersa (@eq-bolsa-palabras), i.e., $\frac{\sum_t \mathbf {v_t}}{\lVert \sum_t \mathbf{v_t} \rVert}$ lo cual resulta en la @eq-bolsa-densa-texto</span>
<span id="cb27-268"><a href="#cb27-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-269"><a href="#cb27-269" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb27-270"><a href="#cb27-270" aria-hidden="true" tabindex="-1"></a>\mathbf u = \mathbf W \mathbf x + \mathbf{w_0},</span>
<span id="cb27-271"><a href="#cb27-271" aria-hidden="true" tabindex="-1"></a>$$ {#eq-bolsa-densa-texto}</span>
<span id="cb27-272"><a href="#cb27-272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-273"><a href="#cb27-273" aria-hidden="true" tabindex="-1"></a>que representa un texto en el vector $\mathbf u \in \mathbb R^M.$</span>
<span id="cb27-274"><a href="#cb27-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-275"><a href="#cb27-275" aria-hidden="true" tabindex="-1"></a>Para algunas representaciones densas, las componentes de la matriz de transformación $\mathcal W$ están asociadas a conceptos, en el caso que se analiza estas están asociadas a palabras claves o emojis. </span>
<span id="cb27-276"><a href="#cb27-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-277"><a href="#cb27-277" aria-hidden="true" tabindex="-1"></a><span class="fu">### Ejemplos </span></span>
<span id="cb27-278"><a href="#cb27-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-279"><a href="#cb27-279" aria-hidden="true" tabindex="-1"></a>Continuando con los ejemplos presentados para la bolsa dispersa (@sec-bolsa-dispersa-ejemplos) en esta sección se hace el análisis con la representación de palabras densa. El primer paso es inicializar la clase que contiene las representaciones densas, esto se hace con la siguiente instrucción. </span>
<span id="cb27-280"><a href="#cb27-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-283"><a href="#cb27-283" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb27-284"><a href="#cb27-284" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb27-285"><a href="#cb27-285" aria-hidden="true" tabindex="-1"></a>dense <span class="op">=</span> DenseBoW(lang<span class="op">=</span><span class="st">'es'</span>,</span>
<span id="cb27-286"><a href="#cb27-286" aria-hidden="true" tabindex="-1"></a>                 voc_size_exponent<span class="op">=</span><span class="dv">15</span>,</span>
<span id="cb27-287"><a href="#cb27-287" aria-hidden="true" tabindex="-1"></a>                 emoji<span class="op">=</span><span class="va">False</span>, keyword<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb27-288"><a href="#cb27-288" aria-hidden="true" tabindex="-1"></a>                 distance_hyperplane<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb27-289"><a href="#cb27-289" aria-hidden="true" tabindex="-1"></a>                 dataset<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb27-290"><a href="#cb27-290" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-291"><a href="#cb27-291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-292"><a href="#cb27-292" aria-hidden="true" tabindex="-1"></a>Para representar un texto en el espacio vectorial denso se utiliza el método <span class="in">`transform`</span>, por ejemplo la siguiente instrucción representa el texto *Es un placer estar platicando con ustedes.* Solo se visualizan los valores de las primeras tres componentes.</span>
<span id="cb27-293"><a href="#cb27-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-296"><a href="#cb27-296" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb27-297"><a href="#cb27-297" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb27-298"><a href="#cb27-298" aria-hidden="true" tabindex="-1"></a>txt1 <span class="op">=</span> <span class="st">'Es un placer estar platicando con ustedes.'</span></span>
<span id="cb27-299"><a href="#cb27-299" aria-hidden="true" tabindex="-1"></a>dense.transform([txt1])[<span class="dv">0</span>, :<span class="dv">3</span>]</span>
<span id="cb27-300"><a href="#cb27-300" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-301"><a href="#cb27-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-302"><a href="#cb27-302" aria-hidden="true" tabindex="-1"></a>Lo primero que se observa es que los valores son negativos, a diferencia del caso disperso donde todos los valores son positivos. En este tipo de representación cada componente está asociada a una palabra las cuales se pueden conocer en el atributo <span class="in">`names`</span>. El siguiente código muestra las tres primeras palabras asociadas al ejemplo anterior. </span>
<span id="cb27-303"><a href="#cb27-303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-306"><a href="#cb27-306" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb27-307"><a href="#cb27-307" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb27-308"><a href="#cb27-308" aria-hidden="true" tabindex="-1"></a>dense.names[:<span class="dv">3</span>]</span>
<span id="cb27-309"><a href="#cb27-309" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-310"><a href="#cb27-310" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-311"><a href="#cb27-311" aria-hidden="true" tabindex="-1"></a>Siguiente la idea de utilizar una nube de palabras para visualizar el vector que representa el texto modelado, La @fig-repr-texto-nube-densa muestra las nubes de palabras generada con las características y sus respectivos valores del texto *Es un placer estar platicando con ustedes.* Durante la generación de la nube de palabras se decidió representar genera una nube de palabras con las palabras con coeficiente negativo más significativo y aquellas con los coeficientes positivos más significativos. Se puede observar que las palabras positivas contienen componentes que están relacionados al enunciado, pero al mismo tiempo leyendo los términos positivos es complicado construir el texto representado. Adicionalmente las términos negativos que se observan en la nube de palabras en su mayoría son hashtags que tiene muy poca relación al texto representado. </span>
<span id="cb27-312"><a href="#cb27-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-315"><a href="#cb27-315" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb27-316"><a href="#cb27-316" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb27-317"><a href="#cb27-317" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Nube de características para el texto *Es un placer estar platicando con ustedes.*</span></span>
<span id="cb27-318"><a href="#cb27-318" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-repr-texto-nube-densa</span></span>
<span id="cb27-319"><a href="#cb27-319" aria-hidden="true" tabindex="-1"></a>values <span class="op">=</span> dense.transform([txt1])</span>
<span id="cb27-320"><a href="#cb27-320" aria-hidden="true" tabindex="-1"></a>names <span class="op">=</span> dense.names</span>
<span id="cb27-321"><a href="#cb27-321" aria-hidden="true" tabindex="-1"></a>tokens_pos <span class="op">=</span> {names[<span class="bu">id</span>]: v <span class="cf">for</span> <span class="bu">id</span>, v <span class="kw">in</span> <span class="bu">enumerate</span>(values[<span class="dv">0</span>]) <span class="cf">if</span> v <span class="op">&gt;</span> <span class="dv">0</span>}</span>
<span id="cb27-322"><a href="#cb27-322" aria-hidden="true" tabindex="-1"></a>tokens_neg <span class="op">=</span> {names[<span class="bu">id</span>]: v <span class="op">*</span> <span class="op">-</span><span class="dv">1</span> <span class="cf">for</span> <span class="bu">id</span>, v <span class="kw">in</span> <span class="bu">enumerate</span>(values[<span class="dv">0</span>]) <span class="cf">if</span> v <span class="op">&lt;</span> <span class="dv">0</span>}</span>
<span id="cb27-323"><a href="#cb27-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-324"><a href="#cb27-324" aria-hidden="true" tabindex="-1"></a>word_pos <span class="op">=</span> WordCloud().generate_from_frequencies(tokens_pos)</span>
<span id="cb27-325"><a href="#cb27-325" aria-hidden="true" tabindex="-1"></a>word_neg <span class="op">=</span> WordCloud().generate_from_frequencies(tokens_neg)</span>
<span id="cb27-326"><a href="#cb27-326" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-327"><a href="#cb27-327" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb27-328"><a href="#cb27-328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-329"><a href="#cb27-329" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> cloud, ax, title <span class="kw">in</span> <span class="bu">zip</span>([word_neg, word_pos],</span>
<span id="cb27-330"><a href="#cb27-330" aria-hidden="true" tabindex="-1"></a>                     [ax1, ax2],</span>
<span id="cb27-331"><a href="#cb27-331" aria-hidden="true" tabindex="-1"></a>                     [<span class="st">'Negativas'</span>, </span>
<span id="cb27-332"><a href="#cb27-332" aria-hidden="true" tabindex="-1"></a>                      <span class="st">'Positivas'</span>]):</span>
<span id="cb27-333"><a href="#cb27-333" aria-hidden="true" tabindex="-1"></a>    ax.imshow(cloud, interpolation<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb27-334"><a href="#cb27-334" aria-hidden="true" tabindex="-1"></a>    ax.grid(<span class="va">False</span>)</span>
<span id="cb27-335"><a href="#cb27-335" aria-hidden="true" tabindex="-1"></a>    ax.tick_params(left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb27-336"><a href="#cb27-336" aria-hidden="true" tabindex="-1"></a>                   labelbottom<span class="op">=</span><span class="va">False</span>, bottom<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb27-337"><a href="#cb27-337" aria-hidden="true" tabindex="-1"></a>    ax.set_title(title)</span>
<span id="cb27-338"><a href="#cb27-338" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-339"><a href="#cb27-339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-340"><a href="#cb27-340" aria-hidden="true" tabindex="-1"></a>Esta representación también permite comparación de similitud entre textos, en el siguiente ejemplo se calcula la similitud entre el texto *Es un placer estar platicando con ustedes.* y los textos *La lluvia genera un caos en la ciudad.* y *Estoy dando una platica en Morelia.* tal y como se hizo para la representación dispersa. Se puede observar que existe una mayor similitud entre los textos que contienen el concepto **plática**, lo cual es equivalente a lo que se observó en el ejemplo con bolsa de palabras discretas, pero los valores son significativamente mayores que en ese caso.</span>
<span id="cb27-341"><a href="#cb27-341" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-342"><a href="#cb27-342" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-345"><a href="#cb27-345" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb27-346"><a href="#cb27-346" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb27-347"><a href="#cb27-347" aria-hidden="true" tabindex="-1"></a>txt1 <span class="op">=</span> <span class="st">'Es un placer estar platicando con ustedes.'</span></span>
<span id="cb27-348"><a href="#cb27-348" aria-hidden="true" tabindex="-1"></a>txt2 <span class="op">=</span> <span class="st">'La lluvia genera un caos en la ciudad.'</span></span>
<span id="cb27-349"><a href="#cb27-349" aria-hidden="true" tabindex="-1"></a>txt3 <span class="op">=</span> <span class="st">'Estoy dando una platica en Morelia.'</span></span>
<span id="cb27-350"><a href="#cb27-350" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> dense.transform([txt1, txt2, txt3])</span>
<span id="cb27-351"><a href="#cb27-351" aria-hidden="true" tabindex="-1"></a>np.dot(X[<span class="dv">0</span>], X[<span class="dv">1</span>]), np.dot(X[<span class="dv">0</span>], X[<span class="dv">2</span>])</span>
<span id="cb27-352"><a href="#cb27-352" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-353"><a href="#cb27-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-354"><a href="#cb27-354" aria-hidden="true" tabindex="-1"></a>Los valores de similitud entre los enunciados anteriores, se puede visualizar en una nube de palabras, utilizando solo las características positivas. La @fig-repr-texto-nube-densa-comp muestra las nubes de palabras generadas, en ellas es complicado comprender la razón por la cual la frases que tiene el concepto *plática* están más cercanas, es probable que la cola de la distribución, es decir, las palabras menos significativas son las que acercan las dos oraciones. </span>
<span id="cb27-355"><a href="#cb27-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-358"><a href="#cb27-358" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb27-359"><a href="#cb27-359" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb27-360"><a href="#cb27-360" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Nube de características positivas.</span></span>
<span id="cb27-361"><a href="#cb27-361" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-repr-texto-nube-densa-comp</span></span>
<span id="cb27-362"><a href="#cb27-362" aria-hidden="true" tabindex="-1"></a>values <span class="op">=</span> dense.transform([txt1, txt2, txt3])</span>
<span id="cb27-363"><a href="#cb27-363" aria-hidden="true" tabindex="-1"></a>names <span class="op">=</span> dense.names</span>
<span id="cb27-364"><a href="#cb27-364" aria-hidden="true" tabindex="-1"></a>tokens_pos <span class="op">=</span> {names[<span class="bu">id</span>]: v <span class="cf">for</span> <span class="bu">id</span>, v <span class="kw">in</span> <span class="bu">enumerate</span>(values[<span class="dv">0</span>]) <span class="cf">if</span> v <span class="op">&gt;</span> <span class="dv">0</span>}</span>
<span id="cb27-365"><a href="#cb27-365" aria-hidden="true" tabindex="-1"></a>tokens_neg <span class="op">=</span> {names[<span class="bu">id</span>]: v <span class="cf">for</span> <span class="bu">id</span>, v <span class="kw">in</span> <span class="bu">enumerate</span>(values[<span class="dv">1</span>]) <span class="cf">if</span> v <span class="op">&gt;</span> <span class="dv">0</span>}</span>
<span id="cb27-366"><a href="#cb27-366" aria-hidden="true" tabindex="-1"></a>tokens_otro <span class="op">=</span> {names[<span class="bu">id</span>]: v <span class="cf">for</span> <span class="bu">id</span>, v <span class="kw">in</span> <span class="bu">enumerate</span>(values[<span class="dv">2</span>]) <span class="cf">if</span> v <span class="op">&gt;</span> <span class="dv">0</span>}</span>
<span id="cb27-367"><a href="#cb27-367" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-368"><a href="#cb27-368" aria-hidden="true" tabindex="-1"></a>word_pos <span class="op">=</span> WordCloud().generate_from_frequencies(tokens_pos)</span>
<span id="cb27-369"><a href="#cb27-369" aria-hidden="true" tabindex="-1"></a>word_neg <span class="op">=</span> WordCloud().generate_from_frequencies(tokens_neg)</span>
<span id="cb27-370"><a href="#cb27-370" aria-hidden="true" tabindex="-1"></a>word_otro <span class="op">=</span> WordCloud().generate_from_frequencies(tokens_otro)</span>
<span id="cb27-371"><a href="#cb27-371" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-372"><a href="#cb27-372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-373"><a href="#cb27-373" aria-hidden="true" tabindex="-1"></a>fig, (ax1, ax2, ax3) <span class="op">=</span> plt.subplots(<span class="dv">1</span>, <span class="dv">3</span>)</span>
<span id="cb27-374"><a href="#cb27-374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-375"><a href="#cb27-375" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> cloud, ax, title <span class="kw">in</span> <span class="bu">zip</span>([word_pos, word_neg, word_otro],</span>
<span id="cb27-376"><a href="#cb27-376" aria-hidden="true" tabindex="-1"></a>                     [ax1, ax2, ax3],</span>
<span id="cb27-377"><a href="#cb27-377" aria-hidden="true" tabindex="-1"></a>                     [<span class="st">'Es un ... ustedes.'</span>, </span>
<span id="cb27-378"><a href="#cb27-378" aria-hidden="true" tabindex="-1"></a>                      <span class="st">'La lluvia ... ciudad.'</span>,</span>
<span id="cb27-379"><a href="#cb27-379" aria-hidden="true" tabindex="-1"></a>                      <span class="st">'Estoy ... Morelia.'</span>]):</span>
<span id="cb27-380"><a href="#cb27-380" aria-hidden="true" tabindex="-1"></a>    ax.imshow(cloud, interpolation<span class="op">=</span><span class="st">'bilinear'</span>)</span>
<span id="cb27-381"><a href="#cb27-381" aria-hidden="true" tabindex="-1"></a>    ax.grid(<span class="va">False</span>)</span>
<span id="cb27-382"><a href="#cb27-382" aria-hidden="true" tabindex="-1"></a>    ax.tick_params(left<span class="op">=</span><span class="va">False</span>, right<span class="op">=</span><span class="va">False</span>, labelleft<span class="op">=</span><span class="va">False</span>,</span>
<span id="cb27-383"><a href="#cb27-383" aria-hidden="true" tabindex="-1"></a>                   labelbottom<span class="op">=</span><span class="va">False</span>, bottom<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb27-384"><a href="#cb27-384" aria-hidden="true" tabindex="-1"></a>    ax.set_title(title)</span>
<span id="cb27-385"><a href="#cb27-385" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-386"><a href="#cb27-386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-387"><a href="#cb27-387" aria-hidden="true" tabindex="-1"></a>Al igual que en el caso disperso se puede calcular la distribución de similitud. Las siguientes instrucciones calcula la similitud coseno entre todos los ejemplos del conjunto de entrenamiento ($\mathcal T$). </span>
<span id="cb27-388"><a href="#cb27-388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-391"><a href="#cb27-391" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb27-392"><a href="#cb27-392" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb27-393"><a href="#cb27-393" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> dense.transform(D)</span>
<span id="cb27-394"><a href="#cb27-394" aria-hidden="true" tabindex="-1"></a>sim <span class="op">=</span> np.dot(X, X.T)</span>
<span id="cb27-395"><a href="#cb27-395" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-396"><a href="#cb27-396" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-397"><a href="#cb27-397" aria-hidden="true" tabindex="-1"></a>La @fig-text-repr-similitud-dense muestra el histograma de las similitudes calculada mediante la bolsa densa. Aquí se puede observar que la gran mayoría de los ejemplos tiene una similitud mayor y tiene una desviación estándar mayor que la vista en la @fig-text-repr-similitud-bow. </span>
<span id="cb27-398"><a href="#cb27-398" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-401"><a href="#cb27-401" aria-hidden="true" tabindex="-1"></a><span class="in">```{python}</span></span>
<span id="cb27-402"><a href="#cb27-402" aria-hidden="true" tabindex="-1"></a><span class="co">#| code-fold: true</span></span>
<span id="cb27-403"><a href="#cb27-403" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: Histograma de la similitud usando bolsa de palabras densas</span></span>
<span id="cb27-404"><a href="#cb27-404" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-text-repr-similitud-dense</span></span>
<span id="cb27-405"><a href="#cb27-405" aria-hidden="true" tabindex="-1"></a>sns.displot(sim.flatten())</span>
<span id="cb27-406"><a href="#cb27-406" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb27-407"><a href="#cb27-407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-408"><a href="#cb27-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-409"><a href="#cb27-409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-410"><a href="#cb27-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-411"><a href="#cb27-411" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-412"><a href="#cb27-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-413"><a href="#cb27-413" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-414"><a href="#cb27-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-415"><a href="#cb27-415" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-416"><a href="#cb27-416" aria-hidden="true" tabindex="-1"></a></span>
</code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
<p><a href="http://creativecommons.org/licenses/by-sa/4.0/"><img src="https://i.creativecommons.org/l/by-sa/4.0/80x15.png" class="img-fluid"></a> <br> Esta obra está bajo una <a href="http://creativecommons.org/licenses/by-sa/4.0/">Licencia Creative Commons Atribución-CompartirIgual 4.0 Internacional</a></p>
</div>
  </div>
</footer>




</body></html>