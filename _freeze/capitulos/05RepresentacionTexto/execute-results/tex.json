{
  "hash": "378bb8f1a03c78eaccf12cc8fbcc248d",
  "result": {
    "markdown": "# Representación de Texto\n\nEl **objetivo** de la unidad es \n\n## Paquetes usados {.unnumbered}\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom EvoMSA import BoW,\\\n                   DenseBoW\nfrom microtc.utils import tweet_iterator\nfrom wordcloud import WordCloud                            \nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pylab as plt\nimport seaborn as sns\n```\n:::\n\n\n\n\n\n\n::: {.content-visible when-format=\"html\"}\n\n---\n\n**Video explicando la unidad**\n\n---\n\n:::\n\n## Bolsa de Palabras Dispersa \n\nLa idea de una bolsa de palabras discretas es que después de haber normalizado y segmentado el texto (@sec-manejando-texto), cada token $t$ sea asociado a un vector único $\\mathbf{v_t} \\in \\mathbb R^d$ donde la $i$-ésima componente, i.e., $\\mathbf{v_t}_i$, es diferente de cero y $\\forall_{j \\neq i} \\mathbf{v_t}_j=0$. Es decir la $i$-ésima componente está asociada al token $t$, se podría pensar que si el vocabulario está ordenado de alguna manera, entonces el token $t$ está en la posición $i$. Por otro lado el valor que contiene la componente se usa para representar alguna característica del token. \n\nEl conjunto de vectores $\\mathbf v$ corresponde al vocabulario, teniendo $d$ diferentes token en el mismo y por definición $\\forall_{i \\neq j} \\mathbf{v_i} \\cdot \\mathbf{v_j} = 0$, donde $\\mathbf{v_i} \\in \\mathbb R^d$, $\\mathbf{v_j} \\in \\mathbb R^d$, y $(\\cdot)$ es el producto punto. Cabe mencionar que cualquier token fuera del vocabulario es descartado. \n\nUsando esta notación, un texto $x$ está representado por una secuencia de tokens, i.e., $(t_1, t_2, \\ldots)$; la secuencia puede tener repeticiones es decir, $t_j = t_k$. Utilizando la característica de que cada token está asociado a un vector $\\mathbf v$, se transforma la secuencia de tokens a una secuencia de vectores (manteniendo las repeticiones), i.e., $(\\mathbf{v_{t_1}}, \\mathbf{v_{t_2}}, \\ldots)$. Finalmente, el texto $x$ se representa como:\n\n$$\n\\mathbf x = \\frac{\\sum_t \\mathbf{v_t}}{\\lVert \\sum_t \\mathbf{v_t} \\rVert},\n$$ {#eq-bolsa-palabras}\n\ndonde la suma se hace para todos los elementos de la secuencia, $\\mathbf x \\in \\mathbb R^d$, y $\\lVert \\mathbf w \\rVert$ es la norma Euclideana del vector $\\mathbf w.$\n\n",
    "supporting": [
      "05RepresentacionTexto_files/figure-pdf"
    ],
    "filters": []
  }
}