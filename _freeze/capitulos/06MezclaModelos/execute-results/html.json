{
  "hash": "d196478eb8dc1a0624551adccd1fbfcc",
  "result": {
    "markdown": "# Mezcla de Modelos\n\nEl **objetivo** de la unidad es \n\n## Paquetes usados {.unnumbered}\n\n::: {#c87c6fca .cell execution_count=1}\n``` {.python .cell-code}\nfrom EvoMSA import BoW,\\\n                   DenseBoW,\\\n                   StackGeneralization\nfrom microtc.utils import tweet_iterator\nfrom IngeoML import CI, SelectFromModelCV\nfrom sklearn.metrics import f1_score,\\\n                            recall_score,\\\n                            precision_score\nfrom wordcloud import WordCloud                            \nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pylab as plt\nimport seaborn as sns\n```\n:::\n\n\n\n\n\n\n::: {.content-visible when-format=\"html\"}\n\n---\n\n**Video explicando la unidad**\n\n---\n\n:::\n\n## Introducción \n\n\n\n\n```{mermaid}\n%%| echo: false\n%%| fig-cap: Diagrama de predicción \n%%| label: fig-prediccion-1-estimador\n\nflowchart LR\n    Repr([Representación]) -- Clasificación --> Clasificador[Clasificador]\n    Repr -- Regresión --> Regresor[Regresor]\n    Clasificador --> Prediccion([Predicción])\n    Regresor --> Prediccion\n```\n\n\n\n\nEl conjunto de datos se puede conseguir en la página de [Delitos](https://ingeotec.github.io/Delitos) aunque en esta dirección es necesario poblar los textos dado que solamente se encuentra el identificador del Tweet.\n\nPara leer los datos del conjunto de entrenamiento y prueba se utilizan las siguientes instrucciones. En la variable `D` se tiene los datos que se utilizarán para entrenar el clasificador basado en la bolsa de palabras y en `Dtest` los datos del conjunto de prueba, que son usados para medir el rendimiento del clasificador.\n\n::: {#d78c2686 .cell execution_count=4}\n``` {.python .cell-code}\nfname = 'delitos/delitos_ingeotec_Es_train.json'\nfname_test = 'delitos/delitos_ingeotec_Es_test.json'\nD = list(tweet_iterator(fname))\nDtest = list(tweet_iterator(fname_test))\n```\n:::\n\n\nEn la siguiente instrucción se observa el primer elemento del conjunto de entrenamiento. Se puede observar que en el campo `text` se encuentra el texto, el campo `klass` representa la etiqueta o clase, donde $0$ representa la clase negativa y $1$ la clase positiva, es decir, la presencia de un delito. El campo `id` es el identificador del Tweet y `annotations` son las clases dadas por los etiquetadores a ese ejemplo.\n\n::: {#a0d47aca .cell execution_count=5}\n``` {.python .cell-code}\nD[81]\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n{'annotations': [0, 0, 0],\n 'id': 1107040319986696195,\n 'klass': 0,\n 'text': 'To loco'}\n```\n:::\n:::\n\n\n## Bolsa de Palabras Dispersa \n\nSe inicia con la creación de un clasificador basado en una bolsa de palabras dispersa, el clasificador es una máquina de soporte vectorial lineal (`LinearSVC`). La siguiente instrucción usa la clase `BoW` para crear este clasificador de texto. El primer paso es seleccionar el lenguaje, en este caso español (es) y después se entrena usando el método `fit`.\n\n::: {#94048817 .cell execution_count=6}\n``` {.python .cell-code}\nbow = BoW(lang='es').fit(D)\n```\n:::\n\n\nHabiendo entrenado el clasificador de texto es momento de utilizarlo para predecir, las siguientes dos instrucciones muestra el uso de la instancia `bow` para predecir clase del texto *me golpearon y robaron la bicicleta en la noche.* Se puede observar que la clase es $1$, lo cual indica que el texto menciona la ejecución de un delito.\n\n::: {#ac88b8ed .cell execution_count=7}\n``` {.python .cell-code}\ntxt = 'me golpearon y robaron la bicicleta en la noche'\nbow.predict([txt])\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\narray([1])\n```\n:::\n:::\n\n\nEl método `predict` recibe una lista de textos a predecir, en la siguiente instrucción se predicen todas las clases del conjunto de prueba (`Dtest`), la predicciones se guardar en la variable `hy_bow`.\n\n::: {#a61d9004 .cell execution_count=8}\n``` {.python .cell-code}\nhy_bow = bow.predict(Dtest)\n```\n:::\n\n\n\n\nHabiendo realizado la predicciones en el conjunto de prueba ($\\mathcal D$), es momento de utilizar estas para medir el rendimiento, en esta ocasión se mide el valor $f_1$ para cada clase. El primer valor ($0.9461$) corresponde a la medida $f_1$ en la clase negativa y el segundo ($0.7460$) corresponde al valor en la clase positiva.\n\n::: {#25b6f536 .cell execution_count=10}\n``` {.python .cell-code}\ny = np.r_[[x['klass'] for x in Dtest]]\nf1_score(y, hy_bow, average=None)\n```\n\n::: {.cell-output .cell-output-display execution_count=10}\n```\narray([0.94612795, 0.74603175])\n```\n:::\n:::\n\n\nCon el objetivo de conocer la variabilidad del rendimiento del clasificador en este conjunto de datos, la siguientes instrucciones calcula el intervalo de confianza; para realizarlo se utiliza la clase `CI` la cual recibe la estadística a calcular, en este caso medida $f_1$. El siguiente paso es llamar a la clase con las entradas para calcular el intervalo, estas corresponden a las mediciones y predicciones del conjunto de prueba. \n\n::: {#9c637d80 .cell execution_count=11}\n``` {.python .cell-code}\nci = CI(statistic=lambda y, hy: f1_score(y, hy, \n                                         average=None))\nci_izq, ci_der = ci(y, hy_bow)\n```\n:::\n\n\n\n\nEl intervalo izquierdo es $[0.9262, 0.6518]$ y el derecho tiene los valores $[0.9634, 0.8182]$. Para complementar la información del intervalo de confianza, la @fig-hist-f1-bow muestra el histograma y la densidad estimada para calcular el intervalo de confianza. Se ve que la varianza en la clase negativa es menor además de que tiene un rendimiento mejor que en la clase positiva. \n\n::: {#cell-fig-hist-f1-bow .cell execution_count=13}\n``` {.python .cell-code code-fold=\"true\"}\ndf_bow = pd.DataFrame(ci.statistic_samples, columns=['f1-neg', 'f1-pos'])\ndf_bow['Tipo'] = 'BoW'\nsns.set_style('whitegrid')\nsns.displot(df_bow, kde=True)\n```\n\n::: {.cell-output .cell-output-display}\n![Histograma de f1 por clase](06MezclaModelos_files/figure-html/fig-hist-f1-bow-output-1.png){#fig-hist-f1-bow width=564 height=470}\n:::\n:::\n\n\nUna manera de poder analizar el comportamiento del clasificador de texto implementado es visualizar en una nube de palabras las características que tienen el mayor peso en la decisión. Esto se realiza en las siguientes instrucciones siendo el primer paso obtener los coeficientes de la máquina de soporte vectorial lineal, los cuales se guardan en la variable `ws`. El segundo componente es el valor de IDF que tiene cada uno de los términos, esto se encuentran en el atributo `BoW.weights` tal y como se muestra en la segunda instrucción del siguiente código. \n\n::: {#22eebc05 .cell execution_count=14}\n``` {.python .cell-code}\nws = bow.estimator_instance.coef_[0]\nidfs = bow.weights\n```\n:::\n\n\nTeniendo los valores del clasificador y del IDF, solamente es necesario obtener su producto y separar los términos positivos de los negativos, tal y como se muestra en el siguiente código. La @fig-nube-tokens muestra las nubes de palabras generadas, cabe mencionar que aquellos términos que tienen como prefijo `q:` corresponden a q-gramas de caracteres y los términos que tienen el caracter `~` corresponden a bigramas de palabras. \n\n::: {#02e35701 .cell execution_count=15}\n``` {.python .cell-code}\ntokens_pos = {name: w * idf\n              for name, idf, w in zip(bow.names,\n                                      idfs, ws)\n              if w > 0}\ntokens_neg = {name: w * idf * -1\n              for name, idf, w in zip(bow.names,\n                                      idfs, ws)\n              if w < 0}\n```\n:::\n\n\nEn la figura se puede observar que las características más importantes corresponden a la presencia de *asesinan*, *asesinan a*, *tiroteo* entre otras y por el lado de palabras relacionadas a la clase negativa se observan *secuestrado*, *asesina*, *un asesino*, entre otras. En @sec-analisis-ejemplo se muestran ejemplos que ayudan a comprender el hecho de que la palabra *asesinan* sea considerada como positiva y por otro lado *asesina* se en la clase negativa.\n\n::: {#cell-fig-nube-tokens .cell execution_count=16}\n``` {.python .cell-code code-fold=\"true\"}\nword_pos = WordCloud().generate_from_frequencies(tokens_pos)\nword_neg = WordCloud().generate_from_frequencies(tokens_neg)\n\nfig, (ax1, ax2) = plt.subplots(1, 2)\n\nfor cloud, ax, title in zip([word_neg, word_pos],\n                     [ax1, ax2],\n                     ['Negativas', 'Positivas']):\n    ax.imshow(cloud, interpolation='bilinear')\n    ax.grid(False)\n    ax.tick_params(left=False, right=False, labelleft=False,\n                   labelbottom=False, bottom=False)\n    ax.set_title(title)\n```\n\n::: {.cell-output .cell-output-display}\n![Nubes de términos positivos y negativos](06MezclaModelos_files/figure-html/fig-nube-tokens-output-1.png){#fig-nube-tokens width=540 height=157}\n:::\n:::\n\n\n## Bolsa de Palabras Densas \n\nEs ahora el turno de hacer el análisis del clasificador de texto que se basado en bolsa de palabras densas. La siguiente instrucción muestra el uso de este clasificador donde se usa una bolsa de palabras con un vocabulario de $2^{15}$ (parámetro `voc_size_exponent=15`) y además se seleccionan como representaciones aquellos entrenados en los conjuntos de emojis (`emoji=True`) y las palabras claves (`keyword=True`). En esta caso, los parámetros del clasificador no son estimados, es decir, no se llama al método `fit`. Esto es porque en este ejemplo se van a seleccionar aquellas representaciones que mejor representan al problema de Delitos utilizando una máquina de soporte vectorial lineal. \n\n::: {#ef64e4e6 .cell execution_count=17}\n``` {.python .cell-code}\ndense = DenseBoW(lang='es',\n                 voc_size_exponent=15,\n                 emoji=True, keyword=True,\n                 dataset=False)\n```\n:::\n\n\nPara seleccionar las características que mejor representan al problema de delitos se utiliza la clase `SelectFromModelCV` la cual usa los coeficientes de la máquina de soporte vectorial para seleccionar las características más representativas, estas corresponden aquellas que tienen los coeficientes más grandes tomando su valor absoluto. La selección se realiza llamando al método `DenseBoW.select` con los parámetros que se observan en las siguientes instrucciones. En particular `SelectFromModelCV` es un método supervisado entonces se utilizarán las clase del conjunto de entrenamiento, y para poder medir el rendimiento de cada conjunto de características seleccionadas se usa una validación cruzada. La última instrucción estima los valores del clasificador con las características seleccionadas. \n\n::: {#de42dd94 .cell execution_count=18}\n``` {.python .cell-code}\nmacro_f1 = lambda y, hy: f1_score(y, hy, average='macro')\nkwargs = dense.estimator_kwargs\nestimator = dense.estimator_class(**kwargs)\nkwargs = dict(estimator=estimator,\n              scoring=macro_f1)\ndense.select(D=D,\n             feature_selection=SelectFromModelCV,\n             feature_selection_kwargs=kwargs)\ndense.fit(D)\n```\n:::\n\n\nComo se mencionó la clase `SelectFromModelCV` selecciona aquellas características que mejor rendimiento dan, la clase mantiene los valores estimados en cada selección, las siguientes instrucciones ejemplifican como obtener los valores de rendimiento en las selecciones. La variable `perf` es una diccionario donde la llave es el número de características y el valor es el rendimiento correspondiente. La @fig-dense-k muestra es rendimiento se puede observar la dinámica donde con un poco menos de $1000$ características se tiene un valor de rendimiento cercano a $0.9$.\n\n::: {#6a8c64b1 .cell execution_count=19}\n``` {.python .cell-code}\nselect = dense.feature_selection\nperf = select.cv_results_\n```\n:::\n\n\n::: {#cell-fig-dense-k .cell execution_count=20}\n``` {.python .cell-code code-fold=\"true\"}\n_ = [{'d': k, 'macro-f1': v} for k, v in perf.items()]\ndf = pd.DataFrame(_)\nax = sns.lineplot(df, x='d', y='macro-f1')\nsns.set_style('whitegrid')\n```\n\n::: {.cell-output .cell-output-display}\n![Rendimiento Variando el Número de Características](06MezclaModelos_files/figure-html/fig-dense-k-output-1.png){#fig-dense-k width=585 height=427}\n:::\n:::\n\n\nDespués de haber seleccionado el número de características, se utiliza un código equivalente al usado en `BoW` para predecir las clases del conjunto de prueba ($\\mathcal G$), tal y como se muestra en la siguiente instrucción. \n\n::: {#215d7f39 .cell execution_count=21}\n``` {.python .cell-code}\nhy_dense = dense.predict(Dtest)\n```\n:::\n\n\nEl rendimiento en $f_1$ del clasificador basado en una bolsa se muestra con el siguiente código. Este valor puntual se complementa con la @fig-hist-f1-bow-dense donde se muestra la distribución de esta medición y se compara con la obtenida con el clasificador de bolsa de palabras dispersa (i.e., `bow`).\n\n::: {#32d81536 .cell execution_count=22}\n``` {.python .cell-code}\nf1_score(y, hy_dense, average=None)\n```\n\n::: {.cell-output .cell-output-display execution_count=22}\n```\narray([0.94158076, 0.75362319])\n```\n:::\n:::\n\n\n::: {#cell-fig-hist-f1-bow-dense .cell execution_count=23}\n``` {.python .cell-code code-fold=\"true\"}\nci(y, hy_dense)\ndf_dense = pd.DataFrame(ci.statistic_samples, columns=['f1-neg', 'f1-pos'])\ndf_dense['Tipo'] = 'Dense'\n\n_ = df_bow.melt(id_vars=['Tipo'], value_name='value', var_name='f1')\n_2 = df_dense.melt(id_vars=['Tipo'], value_name='value', var_name='f1')\n_ = pd.concat((_, _2))\nsns.set_style(\"whitegrid\")\nfig = sns.displot(_, x='value', hue='f1', kde=True, col='Tipo')\n# plt.grid()\n```\n\n::: {.cell-output .cell-output-display}\n![Histogramas de f1 por clase](06MezclaModelos_files/figure-html/fig-hist-f1-bow-dense-output-1.png){#fig-hist-f1-bow-dense width=1044 height=471}\n:::\n:::\n\n\nEn un clasificador basado en palabras densas también se puede comprender su comportamiento mostrando aquellas características que tiene un mayor peso al momento de decidir la clase. En las siguientes instrucciones se agrupan las características positivas y las negativas, utilizando el valor estimado por la máquina de soporte vectorial lineal (`w`). Considerando que cada característica está asociada a una palabra o emoji, entonces se pueden visualizar mediante una nube de palabras.\n\n::: {#8712489c .cell execution_count=24}\n``` {.python .cell-code}\nw = dense.estimator_instance.coef_[0]\nnames = np.array(dense.names)\ncarac_pos = {k: v for k, v in zip(names, w) if v > 0}\ncarac_neg = {k: v * -1 for k, v in zip(names, w) if v < 0}\n```\n:::\n\n\nLa @fig-nube-densa muestra las nubes de palabras de las características positivas y negativas, se puede observar que una característica significativa de la clase positiva corresponde al modelo **robo**, **muere**, entre otros y de la clase negativa se observa **comentando**, **ocurrir*, entre otras. \n\n::: {#cell-fig-nube-densa .cell execution_count=25}\n``` {.python .cell-code code-fold=\"true\"}\nword_pos = WordCloud().generate_from_frequencies(carac_pos)\nword_neg = WordCloud().generate_from_frequencies(carac_neg)\n\nfig, (ax1, ax2) = plt.subplots(1, 2)\n\nfor cloud, ax, title in zip([word_neg, word_pos],\n                     [ax1, ax2],\n                     ['Negativas', 'Positivas']):\n    ax.imshow(cloud, interpolation='bilinear')\n    ax.grid(False)\n    ax.tick_params(left=False, right=False, labelleft=False,\n                   labelbottom=False, bottom=False)\n    ax.set_title(title)\n```\n\n::: {.cell-output .cell-output-display}\n![Nube de características positivas y negativas](06MezclaModelos_files/figure-html/fig-nube-densa-output-1.png){#fig-nube-densa width=540 height=157}\n:::\n:::\n\n\n## Análisis Mediante Ejemplos {#sec-analisis-ejemplo}\n\nHasta el momento se ha presentado un análisis global de los clasificadores dispersos (`bow`) y densos (`dense`), en esta sección se especializa el análisis al nivel de ejemplos. Lo primero que se realiza es ver el valor de la función de decisión, el signo de este valor indica la clase, un valor positivo indica clase positiva y el signo negativo corresponde a la clase negativa. El valor absoluto de la función indica de manera proporcional la distancia que existe al hiperplano que define las clases. Dado que se está utilizando este valor para contrastar el comportamiento de los algoritmos entonces la distancia entre el ejemplo al hiperplano está dado por la función de decisión dividida entre la norma de los coeficientes. La primera línea calcula la norma de los coeficientes estimados tanto para el clasificador disperso (`bow_norm`) y el denso (`dense_norm`)\n\n::: {#f0067944 .cell execution_count=26}\n``` {.python .cell-code}\nbow_norm = np.linalg.norm(bow.estimator_instance.coef_[0])\ndense_norm = np.linalg.norm(dense.estimator_instance.coef_[0])\n```\n:::\n\n\nCon las normas se procederá a calcular la función de decisión para el ejemplo *Asesinan a persona en Jalisco*, este ejemplo es positivo dado que menciona la ocurrencia de un delito. En las siguientes instrucciones se calcula la distancia al hiperplano la cual se puede observar que es positiva indicando que el texto es positivo. \n\n::: {#5251cd67 .cell execution_count=27}\n``` {.python .cell-code}\ntxt = 'Asesinan a persona en Jalisco.'\nbow.decision_function([txt]) / bow_norm\n```\n\n::: {.cell-output .cell-output-display execution_count=27}\n```\narray([[0.03104438]])\n```\n:::\n:::\n\n\nComplementando la distancia del clasificador disperso se presenta la distancia del clasificador denso en el siguiente código. También se puede observar que su valor es positivo, pero este se encuentre más cercano al hiperplano de decisión, lo cual indica que existe una mayor incertidumbre en su clase. \n\n::: {#564ec1e3 .cell execution_count=28}\n``` {.python .cell-code}\ndense.decision_function([txt]) / dense_norm\n```\n\n::: {.cell-output .cell-output-display execution_count=28}\n```\narray([[0.00906055]])\n```\n:::\n:::\n\n\nRealizando el mismo procedimiento pero para texto *La asesina vivía en Jalisco.* Lo primero que se debe de notar es que el texto es negativo dado que se menciona que existe una asesina, pero el texto no indica que se haya cometido algún delito, esta fue una de las reglas que se siguió para etiquetar los textos tanto del conjunto de entrenamiento ($\\mathcal T$) como del conjunto de prueba ($\\mathcal G$). Pero es evidente que el texto anterior y el actual son sintácticamente muy similares, pero con una semántica diferente. \n\nEl siguiente código predice la función de decisión del clasificador disperso, la distancia es el valor absoluto del número presentado y el signo indica el lado del hiperplano, se observa que es negativo, entonces el clasificador indica que pertenece a la clase negativa. \n\n::: {#75695b03 .cell execution_count=29}\n``` {.python .cell-code}\ntxt = 'La asesina vivía en Jalisco.'\nbow.decision_function([txt]) / bow_norm\n```\n\n::: {.cell-output .cell-output-display execution_count=29}\n```\narray([[-0.03643022]])\n```\n:::\n:::\n\n\nEl mismo procedimiento se realiza para el clasificador denso como se indica a continuación, obteniendo también un valor negativo y con una magnitud similar al encontrado por el clasificador disperso. \n\n::: {#9a5b9fcf .cell execution_count=30}\n``` {.python .cell-code}\ndense.decision_function([txt]) / dense_norm\n```\n\n::: {.cell-output .cell-output-display execution_count=30}\n```\narray([[-0.03598119]])\n```\n:::\n:::\n\n\nContinuando con el análisis, se puede visualizar los coeficientes más significativos para realizar la predicción. Por ejemplo, las siguientes instrucciones muestran los 5 coeficientes más significativos para predecir el texto *Asesinan a persona en Jalisco.*\n\n::: {#8bbeb83e .cell execution_count=31}\n``` {.python .cell-code}\ntxt = 'Asesinan a persona en Jalisco.'\nw = bow.estimator_instance.coef_[0]\nvec = bow.bow[txt]\nsorted([(bow.names[k], w[k] * v) for k, v in vec],\n       key=lambda x: np.fabs(x[1]), reverse=True)[:5]\n```\n\n::: {.cell-output .cell-output-display execution_count=31}\n```\n[('asesinan', 0.219594149296318),\n ('asesinan~a', 0.20828291452141962),\n ('q:sina', 0.1451177984417658),\n ('q:n~a~', 0.08388031279342119),\n ('q:an~a', 0.07344382761507427)]\n```\n:::\n:::\n\n\nUn procedimiento equivalente se realiza para el clasificador denso, tal y como se muestra en el siguiente código. \n\n::: {#6ed57f56 .cell execution_count=32}\n``` {.python .cell-code}\nw = dense.estimator_instance.coef_[0]\nvec = dense.transform([txt])[0] * w\nsorted([(dense.names[k], v) for k, v in enumerate(vec)],\n       key=lambda x: np.fabs(x[1]), reverse=True)[:5]\n```\n\n::: {.cell-output .cell-output-display execution_count=32}\n```\n[('ocurrir', 0.06683457750173856),\n ('muere', 0.053880044741064774),\n ('consiguio', -0.05168798790090579),\n ('critican', -0.04459207389659752),\n ('hubieses', -0.04426955144485894)]\n```\n:::\n:::\n\n\nLa @fig-nube-ej-pos muestra la nube de palabras de los términos y características más significativas para la predicción del ejemplo positivo (*Asesinan a persona en Jalisco*). La nube de palabras para el ejemplo negativo (*La asesina vivía en Jalisco*) se muestra en la @fig-nube-ej. La nube de palabras está codificada de la siguiente manera, las palabras que corresponden a la clase positiva está en mayúsculas y las de la clase negativa en minúsculas. Por ejemplo, en @fig-nube-ej-pos se observa que la palabra *asesinan* es relevante para la clasificación del ejemplo así como la característica **ocurrir**.\n\n::: {#cell-fig-nube-ej-pos .cell execution_count=33}\n``` {.python .cell-code code-fold=\"true\"}\ndef codifica(names, vec):\n    carac_pos = dict()\n    for k, v in zip(names, vec):\n        if v > 0:\n            key = f'{k.upper()}'\n        else:\n            key = k\n        carac_pos[key] = np.fabs(v)\n    return carac_pos\ntxt = 'Asesinan a persona en Jalisco.'\n_ = dense.transform([txt])[0] * dense.estimator_instance.coef_[0]\nword_cloud_dense = WordCloud().generate_from_frequencies(codifica(dense.names, _))\n \nw = bow.estimator_instance.coef_[0]\nvec = bow.bow[txt]\ncarac_pos = dict()\nfor k, v in vec:\n    if w[k] > 0:\n        key = f'{bow.names[k].upper()}'\n    else:\n        key = bow.names[k]\n    carac_pos[key] = np.fabs(v * w[k])\n\nword_cloud = WordCloud().generate_from_frequencies(carac_pos)\n\nfig, (ax1, ax2) = plt.subplots(1, 2)\nax1.imshow(word_cloud, interpolation='bilinear')\nax2.imshow(word_cloud_dense, interpolation='bilinear')\nfor ax, title in zip([ax1, ax2], ['BoW', 'DenseBoW']):\n    ax.grid(False)\n    ax.tick_params(left=False, right=False, labelleft=False,\n                   labelbottom=False, bottom=False)\n    ax.set_title(title)\n```\n\n::: {.cell-output .cell-output-display}\n![Nube de características ejemplo positivo](06MezclaModelos_files/figure-html/fig-nube-ej-pos-output-1.png){#fig-nube-ej-pos width=540 height=157}\n:::\n:::\n\n\nEn el caso del ejemplo negativo, la @fig-nube-ej muestra q-gramas de caracteres asociados a la clase positiva y también es evidente la palabra *asesina*. En el caso del clasificador denso también se observan características positivas como **ocurrir** y características negativas como **critican** y **empleados**. \n\n::: {#cell-fig-nube-ej .cell execution_count=34}\n``` {.python .cell-code code-fold=\"true\"}\ntxt = 'La asesina vivía en Jalisco.'\n_ = dense.transform([txt])[0] * dense.estimator_instance.coef_[0]\nword_cloud_dense = WordCloud().generate_from_frequencies(codifica(dense.names, _))\n \nw = bow.estimator_instance.coef_[0]\nvec = bow.bow[txt]\ncarac_pos = dict()\nfor k, v in vec:\n    if w[k] > 0:\n        key = f'{bow.names[k].upper()}'\n    else:\n        key = bow.names[k]\n    carac_pos[key] = np.fabs(v * w[k])\n\nword_cloud = WordCloud().generate_from_frequencies(carac_pos)\n\nfig, (ax1, ax2) = plt.subplots(1, 2)\nax1.imshow(word_cloud, interpolation='bilinear')\nax2.imshow(word_cloud_dense, interpolation='bilinear')\nfor ax, title in zip([ax1, ax2], ['BoW', 'DenseBoW']):\n    ax.grid(False)\n    ax.tick_params(left=False, right=False, labelleft=False,\n                   labelbottom=False, bottom=False)\n    ax.set_title(title)\n```\n\n::: {.cell-output .cell-output-display}\n![Nube de características ejemplo negativo](06MezclaModelos_files/figure-html/fig-nube-ej-output-1.png){#fig-nube-ej width=540 height=157}\n:::\n:::\n\n\n\n\nComplementando los ejemplos anteriores, la @fig-nube-ej-error muestra la nube de palabras obtenidas al calcular la función de decisión del texto *Le acaban de robar la bicicleta a mi hijo.* Se observa que este texto corresponde a la clase positiva y la función de decisión normalizada del clasificador disperso es $-0.0335$ y del clasificador denso corresponde a $-0.0798$. Ambas funciones de decisión indican que la clase es negativa, lo cual es un error. La figura muestra que los q-gramas de caracteres y las características positivas dominan las nubes, pero estas no tienen el peso suficiente para realizar una predicción correcta. \n\n::: {#cell-fig-nube-ej-error .cell execution_count=36}\n``` {.python .cell-code code-fold=\"true\"}\ntxt = 'Le acaban de robar la bicicleta a mi hijo.'\n_ = dense.transform([txt])[0] * dense.estimator_instance.coef_[0]\nword_cloud_dense = WordCloud().generate_from_frequencies(codifica(dense.names, _))\n \nw = bow.estimator_instance.coef_[0]\nvec = bow.bow[txt]\ncarac_pos = dict()\nfor k, v in vec:\n    if w[k] > 0:\n        key = f'{bow.names[k].upper()}'\n    else:\n        key = bow.names[k]\n    carac_pos[key] = np.fabs(v * w[k])\n\nword_cloud = WordCloud().generate_from_frequencies(carac_pos)\n\nfig, (ax1, ax2) = plt.subplots(1, 2)\nax1.imshow(word_cloud, interpolation='bilinear')\nax2.imshow(word_cloud_dense, interpolation='bilinear')\nfor ax, title in zip([ax1, ax2], ['BoW', 'DenseBoW']):\n    ax.grid(False)\n    ax.tick_params(left=False, right=False, labelleft=False,\n                   labelbottom=False, bottom=False)\n    ax.set_title(title)\n```\n\n::: {.cell-output .cell-output-display}\n![Nube de características en un ejemplo positivo con predicción negativa](06MezclaModelos_files/figure-html/fig-nube-ej-error-output-1.png){#fig-nube-ej-error width=540 height=157}\n:::\n:::\n\n\n## Combinando Modelos\n\n\n\n\n```{mermaid}\n%%| echo: false\n%%| fig-cap: Diagrama de predicción en mezcla de modelos\n%%| label: fig-prediccion-1-estimador\n\nflowchart TB\n    Conc[Concatenación]\n    Representación --> Estimadores --> Conc\n    Conc --> Predicción\n    subgraph Representación [Representaciones]\n        direction TB\n        Repr1([Representación 1])\n        Repr2([Representación 2])\n        ReprI([...])\n        ReprM([Representación M])\n    end\n    subgraph Estimadores\n        direction TB    \n        Est1[Estimador 1] \n        Est2[Estimador 2]\n        EstI[...]\n        EstM[Estimador M]\n    end\n    subgraph Predicción [Etapa de Predicción]\n        direction TB\n        Entrada\n        Entrada -- Clasificación --> Clasificador[Clasificador]\n        Entrada -- Regresión --> Regresor[Regresor]\n        Clasificador --> Prediccion([Predicción])\n        Regresor --> Prediccion\n    end\n```\n\n\n\n\nLa siguiente pregunta es conocer si los modelos anteriores se pueden combinar para realizar una mejor predicción. En esta sección se utiliza la técnica de Stack Generalization (@Wolpert1992StackedGeneralization, @EvoMSA) para combinar los dos modelos. La siguiente linea entrena el clasificador, el cual recibe como parámetros los clasificador a juntar. \n\n::: {#ac86bd45 .cell execution_count=37}\n``` {.python .cell-code}\nstack = StackGeneralization([bow, dense]).fit(D)\n```\n:::\n\n\nSiguiendo el procedimiento de los clasificadores dispersos y densos, la siguiente linea predice la clase de los ejemplos del conjunto de prueba y calcula su rendimiento en términos de la medida $f_1$.\n\n::: {#91aaf598 .cell execution_count=38}\n``` {.python .cell-code}\nhy_stack = stack.predict(Dtest)\nf1_score(y, hy_stack, average=None)\n```\n\n::: {.cell-output .cell-output-display execution_count=38}\n```\narray([0.94791667, 0.79166667])\n```\n:::\n:::\n\n\nPara poder comparar el rendimiento de los tres clasificadores desarrollados, la @tbl-performance-recall-precision-delitos presenta el rendimiento con las medidas recall y precision en las dos clases. Se puede observar que el `bow` tiene el mejor recall en la clase negativa y mejor precision en la clase positiva. Por otro lado el mejor recall en la clase positiva y precision en la clase negativa lo tiene `stack`.\n\n::: {#tbl-performance-recall-precision-delitos .cell tbl-cap='Rendimiento' execution_count=39}\n\n::: {.cell-output .cell-output-display execution_count=39}\n|              |   Recall neg | Recall pos | Precision neg | Precision pos |\n|--------------|--------------|------------|---------------|---------------|\n|`bow`|$0.9894$ | $0.6184$ | $0.9065$ | $0.9400$|\n|`dense`|$0.9648$ | $0.6842$ | $0.9195$ | $0.8387$|\n|`stack`|$0.9613$ | $0.7500$ | $0.9349$ | $0.8382$|\n:::\n:::\n\n\nCon respecto al rendimiento en términos de $f_1$, la @tbl-performance-f1-delitos presenta la información con respecto a cada clase y la última columna contiene el macro-$f_1$. Los valores indican que en la clase positiva el mejor valor corresponde a `stack` lo cual se ve reflejado en el macro-$f_1$. El algoritmo de Stack Generalization nos indica que se hizo una mejora en la predicción de la clase positiva y la clase negativa se mantuvo constante al menos con respecto de la medida $f_1$.\n\n::: {#tbl-performance-f1-delitos .cell tbl-cap='Rendimiento' execution_count=40}\n\n::: {.cell-output .cell-output-display execution_count=40}\n|              | f1 neg | f1 pos | macro-f1 |\n|--------------|--------|--------|----------|\n|`bow`|$0.9461$ | $0.7460$ | $0.8461$|\n|`dense`|$0.9416$ | $0.7536$ | $0.8476$|\n|`stack`|$0.9479$ | $0.7917$ | $0.8698$|\n:::\n:::\n\n\n",
    "supporting": [
      "06MezclaModelos_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}