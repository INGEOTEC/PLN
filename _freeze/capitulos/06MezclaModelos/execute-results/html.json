{
  "hash": "674135f08478fdec9568f56fcdf0e488",
  "result": {
    "markdown": "# Mezcla de Modelos\n\nEl **objetivo** de la unidad es \n\n## Paquetes usados {.unnumbered}\n\n::: {#1a937b4c .cell execution_count=1}\n``` {.python .cell-code}\nfrom EvoMSA import BoW, DenseBoW\nfrom microtc.utils import tweet_iterator\nfrom IngeoML import CI, SelectFromModelCV\nfrom sklearn.metrics import f1_score,\\\n                            recall_score,\\\n                            precision_score\nfrom wordcloud import WordCloud                            \nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pylab as plt\nimport seaborn as sns\n```\n:::\n\n\n\n\n\n\n::: {.content-visible when-format=\"html\"}\n\n---\n\n**Video explicando la unidad**\n\n---\n\n:::\n\n## Conjunto de Datos \n\nEl conjunto de datos se puede conseguir en la página de [Delitos](https://ingeotec.github.io/Delitos) aunque en esta dirección es necesario poblar los textos dado que solamente se encuentra el identificador del Tweet.\n\nPara leer los datos del conjunto de entrenamiento y prueba se utilizan las siguientes instrucciones. En la variable `D` se tiene los datos que se utilizarán para entrenar el clasificador basado en la bolsa de palabras y en `Dtest` los datos del conjunto de prueba, que son usados para medir el rendimiento del clasificador.\n\n::: {#db985250 .cell execution_count=4}\n``` {.python .cell-code}\nfname = 'delitos/delitos_ingeotec_Es_train.json'\nfname_test = 'delitos/delitos_ingeotec_Es_test.json'\nD = list(tweet_iterator(fname))\nDtest = list(tweet_iterator(fname_test))\n```\n:::\n\n\nEn la siguiente instrucción se observa el primer elemento del conjunto de entrenamiento. Se puede observar que en el campo `text` se encuentra el texto, el campo `klass` representa la etiqueta o clase, donde $0$ representa la clase negativa y $1$ la clase positiva, es decir, la presencia de un delito. El campo `id` es el identificador del Tweet y `annotations` son las clases dadas por los etiquetadores a ese ejemplo.\n\n::: {#b11f5df0 .cell execution_count=5}\n``` {.python .cell-code}\nD[81]\n```\n\n::: {.cell-output .cell-output-display execution_count=5}\n```\n{'annotations': [0, 0, 0],\n 'id': 1107040319986696195,\n 'klass': 0,\n 'text': 'To loco'}\n```\n:::\n:::\n\n\n## Bolsa de Palabras Dispersa \n\n::: {#5593409e .cell execution_count=6}\n``` {.python .cell-code}\nbow = BoW(lang='es').fit(D)\n```\n:::\n\n\n::: {#38d55736 .cell execution_count=7}\n``` {.python .cell-code}\ntxt = 'me golpearon y robaron la bicicleta en la noche'\nbow.predict([txt])\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```\narray([1])\n```\n:::\n:::\n\n\n::: {#fb4a3e6b .cell execution_count=8}\n``` {.python .cell-code}\nhy_bow = bow.predict(Dtest)\n```\n:::\n\n\n::: {#d558472b .cell execution_count=9}\n``` {.python .cell-code}\ny = np.r_[[x['klass'] for x in Dtest]]\nf1_score(y, hy_bow, average=None)\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```\narray([0.94612795, 0.74603175])\n```\n:::\n:::\n\n\n::: {#c19281fc .cell execution_count=10}\n``` {.python .cell-code}\nci = CI(statistic=lambda y, hy: f1_score(y, hy, \n                                         average=None))\nci_izq, ci_der = ci(y, hy_bow)\n```\n:::\n\n\n\n\nEl intervalo izquierdo es $[0.9253, 0.6530]$ y el derecho tiene los valores $[0.9635, 0.8222]$.\n\n::: {#cell-hist-f1-bow .cell execution_count=12}\n``` {.python .cell-code code-fold=\"true\"}\ndf_bow = pd.DataFrame(ci.statistic_samples, columns=['f1-neg', 'f1-pos'])\ndf_bow['Tipo'] = 'BoW'\nsns.set_style('whitegrid')\nsns.displot(df_bow, kde=True)\n```\n\n::: {.cell-output .cell-output-display}\n![Histograma de f1 por clase](06MezclaModelos_files/figure-html/hist-f1-bow-output-1.png){#hist-f1-bow width=564 height=470}\n:::\n:::\n\n\n::: {#d77b1d50 .cell execution_count=13}\n``` {.python .cell-code}\nws = bow.estimator_instance.coef_[0]\nidfs = bow.weights\n```\n:::\n\n\n::: {#a27d15eb .cell execution_count=14}\n``` {.python .cell-code}\ntokens_pos = {name: w * idf\n              for name, idf, w in zip(bow.names, idfs, ws)\n              if w > 0}\ntokens_neg = {name: w * idf * -1\n              for name, idf, w in zip(bow.names, idfs, ws)\n              if w < 0}\n```\n:::\n\n\n::: {#cell-fig-nube-tokens-pos .cell execution_count=15}\n``` {.python .cell-code code-fold=\"true\"}\nword_cloud = WordCloud().generate_from_frequencies(tokens_pos)\nplt.imshow(word_cloud, interpolation='bilinear')\nplt.tick_params(left=False, right=False, labelleft=False,\n                labelbottom=False, bottom=False)\nplt.grid(False)\n```\n\n::: {.cell-output .cell-output-display}\n![Nube de tokens positivos](06MezclaModelos_files/figure-html/fig-nube-tokens-pos-output-1.png){#fig-nube-tokens-pos width=540 height=280}\n:::\n:::\n\n\n::: {#cell-fig-nube-tokens-neg .cell execution_count=16}\n``` {.python .cell-code code-fold=\"true\"}\nword_cloud = WordCloud().generate_from_frequencies(tokens_neg)\nplt.imshow(word_cloud, interpolation='bilinear')\nplt.tick_params(left=False, right=False, labelleft=False,\n                labelbottom=False, bottom=False)\nplt.grid(False)                \n```\n\n::: {.cell-output .cell-output-display}\n![Nube de tokens negativas](06MezclaModelos_files/figure-html/fig-nube-tokens-neg-output-1.png){#fig-nube-tokens-neg width=540 height=280}\n:::\n:::\n\n\n## Bolsa de Palabras Densas \n\n::: {#51058dcb .cell execution_count=17}\n``` {.python .cell-code}\ndense = DenseBoW(lang='es',\n                 voc_size_exponent=15,\n                 dataset=False)\n```\n:::\n\n\n::: {#568c6012 .cell execution_count=18}\n``` {.python .cell-code}\nmacro_f1 = lambda y, hy: f1_score(y, hy, average='macro')\nkwargs = dense.estimator_kwargs\nestimator = dense.estimator_class(**kwargs)\nkwargs = dict(estimator=estimator,\n              scoring=macro_f1)\ndense.select(D=D,\n             feature_selection=SelectFromModelCV,\n             feature_selection_kwargs=kwargs)\ndense.fit(D)\n```\n:::\n\n\n::: {#6063cd1f .cell execution_count=19}\n``` {.python .cell-code}\nselect = dense.feature_selection\nperf = select.cv_results_\n```\n:::\n\n\n::: {#cell-fig-dense-k .cell execution_count=20}\n``` {.python .cell-code code-fold=\"true\"}\n_ = [{'d': k, 'macro-f1': v} for k, v in perf.items()]\ndf = pd.DataFrame(_)\nax = sns.lineplot(df, x='d', y='macro-f1')\nsns.set_style('whitegrid')\n```\n\n::: {.cell-output .cell-output-display}\n![Rendimiento Variando el Número de Características](06MezclaModelos_files/figure-html/fig-dense-k-output-1.png){#fig-dense-k width=585 height=427}\n:::\n:::\n\n\n::: {#226312cd .cell execution_count=21}\n``` {.python .cell-code}\nhy_dense = dense.predict(Dtest)\n```\n:::\n\n\n::: {#110e6210 .cell execution_count=22}\n``` {.python .cell-code}\nf1_score(y, hy_dense, average=None)\n```\n\n::: {.cell-output .cell-output-display execution_count=22}\n```\narray([0.94158076, 0.75362319])\n```\n:::\n:::\n\n\n::: {#cell-hist-f1-bow-dense .cell execution_count=23}\n``` {.python .cell-code code-fold=\"true\"}\nci(y, hy_dense)\ndf_dense = pd.DataFrame(ci.statistic_samples, columns=['f1-neg', 'f1-pos'])\ndf_dense['Tipo'] = 'Dense'\n\n_ = df_bow.melt(id_vars=['Tipo'], value_name='value', var_name='f1')\n_2 = df_dense.melt(id_vars=['Tipo'], value_name='value', var_name='f1')\n_ = pd.concat((_, _2))\nsns.set_style(\"whitegrid\")\nfig = sns.displot(_, x='value', hue='f1', kde=True, col='Tipo')\n# plt.grid()\n```\n\n::: {.cell-output .cell-output-display}\n![Histogramas de f1 por clase](06MezclaModelos_files/figure-html/hist-f1-bow-dense-output-1.png){#hist-f1-bow-dense width=1044 height=471}\n:::\n:::\n\n\n::: {#tbl-performance-bow-dense .cell tbl-cap='Rendimiento' execution_count=24}\n\n::: {.cell-output .cell-output-display execution_count=24}\n|              |   Recall neg | Recall pos | Precision neg | Precision pos |\n|--------------|--------------|------------|---------------|---------------|\n|`BoW`|$0.9894$ | $0.6184$ | $0.9065$ | $0.9400$|\n|`DenseBoW`|$0.9648$ | $0.6842$ | $0.9195$ | $0.8387$|\n:::\n:::\n\n\n",
    "supporting": [
      "06MezclaModelos_files/figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}